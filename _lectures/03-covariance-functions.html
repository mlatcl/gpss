---
title: "Covariance Functions and Hyperparameter Optimization"
abstract: "<p>In this talk we review covariance functions and
optimization of the GP log likelihoood.</p>"
author:
- given: Neil D.
  family: Lawrence
  url: 
  institute: 
  twitter: 
  gscholar: 
  orcid: 
edit_url: https://github.com/mlatcl/gpss/edit/gh-pages/_lamd/covariance-functions.md
week: 3
featured_image: slides/diagrams/kern/sinc_covariance.gif
reveal: 03-covariance-functions.slides.html
transition: None
ipynb: 03-covariance-functions.ipynb
pptx: 03-covariance-functions.pptx
layout: lecture
categories:
- notes
---



<!-- Do not edit this file locally. -->
<!---->
<!-- Do not edit this file locally. -->
<!-- Do not edit this file locally. -->
<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->
<!--

-->
<!-- To compile -->
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install gpy</span></code></pre></div>
<h2 id="gpy-a-gaussian-process-framework-in-python">GPy: A Gaussian
Process Framework in Python</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Gaussian processes are a flexible tool for non-parametric analysis
with uncertainty. The GPy software was started in Sheffield to provide a
easy to use interface to GPs. One which allowed the user to focus on the
modelling rather than the mathematics.</p>
<div class="figure">
<div id="gpy-software-figure" class="figure-frame">
<div class="centered" style="">
<img class="" src="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gpy.png" width="70%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</div>
<div id="gpy-software-magnify" class="magnify"
onclick="magnifyFigure(&#39;gpy-software&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gpy-software-caption" class="caption-frame">
<p>Figure: GPy is a BSD licensed software code base for implementing
Gaussian process models in Python. It is designed for teaching and
modelling. We welcome contributions which can be made through the GitHub
repository <a href="https://github.com/SheffieldML/GPy"
class="uri">https://github.com/SheffieldML/GPy</a></p>
</div>
</div>
<p>GPy is a BSD licensed software code base for implementing Gaussian
process models in python. This allows GPs to be combined with a wide
variety of software libraries.</p>
<p>The software itself is available on <a
href="https://github.com/SheffieldML/GPy">GitHub</a> and the team
welcomes contributions.</p>
<p>The aim for GPy is to be a probabilistic-style programming language,
i.e., you specify the model rather than the algorithm. As well as a
large range of covariance functions the software allows for non-Gaussian
likelihoods, multivariate outputs, dimensionality reduction and
approximations for larger data sets.</p>
<p>The documentation for GPy can be found <a
href="https://gpy.readthedocs.io/en/latest/">here</a>.</p>
<h2 id="the-importance-of-the-covariance-function">The Importance of the
Covariance Function</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-covariance-function-importance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-covariance-function-importance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The covariance function encapsulates our assumptions about the data.
The equations for the distribution of the prediction function, given the
training observations, are highly sensitive to the covariation between
the test locations and the training locations as expressed by the matrix
<span class="math inline">\(\mathbf{K}_*\)</span>. We defined a matrix
<span class="math inline">\(\mathbf{A}\)</span> which allowed us to
express our conditional mean in the form, <span class="math display">\[
\boldsymbol{ \mu}_f= \mathbf{A}^\top \mathbf{ y},
\]</span> where <span class="math inline">\(\mathbf{ y}\)</span> were
our <em>training observations</em>. In other words our mean predictions
are always a linear weighted combination of our <em>training data</em>.
The weights are given by computing the covariation between the training
and the test data (<span class="math inline">\(\mathbf{K}_*\)</span>)
and scaling it by the inverse covariance of the training data
observations, <span class="math inline">\(\left[\mathbf{K}+ \sigma^2
\mathbf{I}\right]^{-1}\)</span>. This inverse is the main computational
object that needs to be resolved for a Gaussian process. It has a
computational burden which is <span
class="math inline">\(O(n^3)\)</span> and a storage burden which is
<span class="math inline">\(O(n^2)\)</span>. This makes working with
Gaussian processes computationally intensive for the situation where
<span class="math inline">\(n&gt;10,000\)</span>.</p>
<div class="figure">
<div id="intro-to-gps-figure" class="figure-frame">
<iframe width="600" height="450" src="https://www.youtube.com/embed/ewJ3AxKclOg?start=" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
</div>
<div id="intro-to-gps-magnify" class="magnify"
onclick="magnifyFigure(&#39;intro-to-gps&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="intro-to-gps-caption" class="caption-frame">
<p>Figure: Introduction to Gaussian processes given by Neil Lawrence at
the 2014 Gaussian process Winter School at the University of
Sheffield.</p>
</div>
</div>
<h2 id="improving-the-numerics">Improving the Numerics</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-numerics-and-optimization.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-numerics-and-optimization.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>In practice we shouldn’t be using matrix inverse directly to solve
the GP system. One more stable way is to compute the <em>Cholesky
decomposition</em> of the kernel matrix. The log determinant of the
covariance can also be derived from the Cholesky decomposition.</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> update_inverse</span></code></pre></div>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>GP.update_inverse <span class="op">=</span> update_inverse</span></code></pre></div>
<h2 id="capacity-control">Capacity Control</h2>
<p>Gaussian processes are sometimes seen as part of a wider family of
methods known as kernel methods. Kernel methods are also based around
covariance functions, but in the field they are known as Mercer kernels.
Mercer kernels have interpretations as inner products in potentially
infinite dimensional Hilbert spaces. This interpretation arises because,
if we take <span class="math inline">\(\alpha=1\)</span>, then the
kernel can be expressed as <span class="math display">\[
\mathbf{K}= \boldsymbol{ \Phi}\boldsymbol{ \Phi}^\top
\]</span> which imples the elements of the kernel are given by, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \boldsymbol{ \phi}(\mathbf{
x})^\top \boldsymbol{ \phi}(\mathbf{ x}^\prime).
\]</span> So we see that the kernel function is developed from an inner
product between the basis functions. Mercer’s theorem tells us that any
valid <em>positive definite function</em> can be expressed as this inner
product but with the caveat that the inner product could be <em>infinite
length</em>. This idea has been used quite widely to <em>kernelize</em>
algorithms that depend on inner products. The kernel functions are
equivalent to covariance functions and they are parameterized
accordingly. In the kernel modeling community it is generally accepted
that kernel parameter estimation is a difficult problem and the normal
solution is to cross validate to obtain parameters. This can cause
difficulties when a large number of kernel parameters need to be
estimated. In Gaussian process modelling kernel parameter estimation (in
the simplest case proceeds) by maximum likelihood. This involves taking
gradients of the likelihood with respect to the parameters of the
covariance function.</p>
<h2 id="gradients-of-the-likelihood">Gradients of the Likelihood</h2>
<p>The easiest conceptual way to obtain the gradients is a two step
process. The first step involves taking the gradient of the likelihood
with respect to the covariance function, the second step involves
considering the gradient of the covariance function with respect to its
parameters.</p>
<h2 id="overall-process-scale">Overall Process Scale</h2>
<p>In general we won’t be able to find parameters of the covariance
function through fixed point equations, we will need to do gradient
based optimization.</p>
<h2 id="capacity-control-and-data-fit">Capacity Control and Data
Fit</h2>
<p>The objective function can be decomposed into two terms, a capacity
control term, and a data fit term. The capacity control term is the log
determinant of the covariance. The data fit term is the matrix inner
product between the data and the inverse covariance.</p>
<h2 id="learning-covariance-parameters">Learning Covariance
Parameters</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Can we determine covariance parameters from the data?</p>
<p><span class="math display">\[
\mathcal{N}\left(\mathbf{
y}|\mathbf{0},\mathbf{K}\right)=\frac{1}{(2\pi)^\frac{n}{2}{\det{\mathbf{K}}^{\frac{1}{2}}}}{\exp\left(-\frac{\mathbf{
y}^{\top}\mathbf{K}^{-1}\mathbf{ y}}{2}\right)}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
    \mathcal{N}\left(\mathbf{
y}|\mathbf{0},\mathbf{K}\right)=\frac{1}{(2\pi)^\frac{n}{2}\color{blue}{\det{\mathbf{K}}^{\frac{1}{2}}}}\color{red}{\exp\left(-\frac{\mathbf{
y}^{\top}\mathbf{K}^{-1}\mathbf{ y}}{2}\right)}
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
    \log \mathcal{N}\left(\mathbf{
y}|\mathbf{0},\mathbf{K}\right)=&amp;\color{blue}{-\frac{1}{2}\log\det{\mathbf{K}}}\color{red}{-\frac{\mathbf{
y}^{\top}\mathbf{K}^{-1}\mathbf{ y}}{2}} \\ &amp;-\frac{n}{2}\log2\pi
\end{aligned}
\]</span></p>
<p><span class="math display">\[
E(\boldsymbol{ \theta}) = \color{blue}{\frac{1}{2}\log\det{\mathbf{K}}}
+ \color{red}{\frac{\mathbf{ y}^{\top}\mathbf{K}^{-1}\mathbf{ y}}{2}}
\]</span></p>
<h2 id="capacity-control-through-the-determinant">Capacity Control
through the Determinant</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-capacity.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-capacity.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The parameters are <em>inside</em> the covariance function (matrix).
<span class="math display">\[k_{i, j} = k(\mathbf{ x}_i, \mathbf{ x}_j;
\boldsymbol{ \theta})\]</span></p>
<p><span> <span class="math display">\[\mathbf{K}=
\mathbf{R}\boldsymbol{ \Lambda}^2 \mathbf{R}^\top\]</span></span></p>
<table>
<tr>
<td width="50%">
<div class="centered" style="">
<img class="negate" src="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimize-eigen.png" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
<td width="50%">
<span class="math inline">\(\boldsymbol{ \Lambda}\)</span> represents
distance on axes. <span class="math inline">\(\mathbf{R}\)</span> gives
rotation.
</td>
</tr>
</table>
<ul>
<li><span class="math inline">\(\boldsymbol{ \Lambda}\)</span> is
<em>diagonal</em>, <span
class="math inline">\(\mathbf{R}^\top\mathbf{R}=
\mathbf{I}\)</span>.</li>
<li>Useful representation since <span
class="math inline">\(\det{\mathbf{K}} = \det{\boldsymbol{ \Lambda}^2} =
\det{\boldsymbol{ \Lambda}}^2\)</span>.</li>
</ul>
<div class="figure">
<div id="gp-optimise-determinant-figure-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise-determinant009.svg" width="80%" style=" ">
</object>
</div>
<div id="gp-optimise-determinant-figure-magnify" class="magnify"
onclick="magnifyFigure(&#39;gp-optimise-determinant-figure&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gp-optimise-determinant-figure-caption" class="caption-frame">
<p>Figure: The determinant of the covariance is dependent only on the
eigenvalues. It represents the ‘footprint’ of the Gaussian.</p>
</div>
</div>
<h2 id="quadratic-data-fit">Quadratic Data Fit</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="gp-optimise-quadratic-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise-quadratic002.svg" width="80%" style=" ">
</object>
</div>
<div id="gp-optimise-quadratic-magnify" class="magnify"
onclick="magnifyFigure(&#39;gp-optimise-quadratic&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gp-optimise-quadratic-caption" class="caption-frame">
<p>Figure: The data fit term of the Gaussian process is a quadratic loss
centered around zero. This has eliptical contours, the principal axes of
which are given by the covariance matrix.</p>
</div>
</div>
<h2 id="data-fit-term">Data Fit Term</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit-capacity.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit-capacity.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="figure">
<div id="gp-optimise-figure" class="figure-frame">
<table>
<tr>
<td width="50%">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise006.svg" width="100%" style=" ">
</object>
</td>
<td width="50%">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise010.svg" width="100%" style=" ">
</object>
</td>
</tr>
</table>
<table>
<tr>
<td width="50%">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise016.svg" width="100%" style=" ">
</object>
</td>
<td width="50%">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/gp-optimise021.svg" width="100%" style=" ">
</object>
</td>
</tr>
</table>
</div>
<div id="gp-optimise-magnify" class="magnify"
onclick="magnifyFigure(&#39;gp-optimise&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="gp-optimise-caption" class="caption-frame">
<p>Figure: Variation in the data fit term, the capacity term and the
negative log likelihood for different lengthscales.</p>
</div>
</div>
<h2 id="exponentiated-quadratic-covariance">Exponentiated Quadratic
Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/eq-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/eq-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The exponentiated quadratic covariance, also known as the Gaussian
covariance or the RBF covariance and the squared exponential. Covariance
between two points is related to the negative exponential of the squared
distnace between those points. This covariance function can be derived
in a few different ways: as the infinite limit of a radial basis
function neural network, as diffusion in the heat equation, as a
Gaussian filter in <em>Fourier space</em> or as the composition as a
series of linear filters applied to a base function.</p>
<p>The covariance takes the following form, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha \exp\left(-\frac{\left\Vert
\mathbf{ x}-\mathbf{ x}^\prime \right\Vert_2^2}{2\ell^2}\right)
\]</span> where <span class="math inline">\(\ell\)</span> is the
<em>length scale</em> or <em>time scale</em> of the process and <span
class="math inline">\(\alpha\)</span> represents the overall process
variance.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\exp\left(-\frac{\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2^2}{2\ell^2}\right)\]</span>
</center>
<div class="figure">
<div id="eq-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/eq_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/eq_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="eq-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;eq-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="eq-covariance-plot-caption" class="caption-frame">
<p>Figure: The exponentiated quadratic covariance function.</p>
</div>
</div>
<h2 id="where-did-this-covariance-matrix-come-from">Where Did This
Covariance Matrix Come From?</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/computing-rbf-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/computing-rbf-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><span class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha \exp\left(-\frac{\left\Vert
\mathbf{ x}- \mathbf{
x}^\prime\right\Vert^2_2}{2\ell^2}\right)\]</span></p>
<div class="figure">
<div id="computing-eq-three-covariance2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//kern/computing_eq_three_covariance016.svg" width="80%" style=" ">
</object>
</div>
<div id="computing-eq-three-covariance2-magnify" class="magnify"
onclick="magnifyFigure(&#39;computing-eq-three-covariance2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="computing-eq-three-covariance2-caption" class="caption-frame">
<p>Figure: Entrywise fill in of the covariance matrix from the
covariance function.</p>
</div>
</div>
<div class="figure">
<div id="computing-eq-four-covariance2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//kern/computing_eq_four_covariance027.svg" width="80%" style=" ">
</object>
</div>
<div id="computing-eq-four-covariance2-magnify" class="magnify"
onclick="magnifyFigure(&#39;computing-eq-four-covariance2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="computing-eq-four-covariance2-caption" class="caption-frame">
<p>Figure: Entrywise fill in of the covariance matrix from the
covariance function.</p>
</div>
</div>
<div class="figure">
<div id="computing-eq-three-2-covariance2-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//kern/computing_eq_three_2_covariance016.svg" width="80%" style=" ">
</object>
</div>
<div id="computing-eq-three-2-covariance2-magnify" class="magnify"
onclick="magnifyFigure(&#39;computing-eq-three-2-covariance2&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="computing-eq-three-2-covariance2-caption"
class="caption-frame">
<p>Figure: Entrywise fill in of the covariance matrix from the
covariance function.</p>
</div>
</div>
<h2 id="brownian-covariance">Brownian Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/brownian-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/brownian-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> brownian_cov</span></code></pre></div>
<p>Brownian motion is also a Gaussian process. It follows a Gaussian
random walk, with diffusion occuring at each time point driven by a
Gaussian input. This implies it is both Markov and Gaussian. The
covariance function for Brownian motion has the form <span
class="math display">\[
k(t, t^\prime)=\alpha \min(t, t^\prime)
\]</span></p>
<center>
<span class="math display">\[k(t, t^\prime)=\alpha \min(t,
t^\prime)\]</span>
</center>
<div class="figure">
<div id="brownian-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/brownian_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/brownian_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="brownian-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;brownian-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="brownian-covariance-plot-caption" class="caption-frame">
<p>Figure: Brownian motion covariance function.</p>
</div>
</div>
<h2 id="where-did-this-covariance-matrix-come-from-1">Where did this
covariance matrix come from?</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/precision-matrices.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/precision-matrices.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><strong>Markov Process</strong></p>
<p><strong>Visualization of inverse covariance (precision).</strong></p>
<ul>
<li><p>Precision matrix is sparse: only neighbours in matrix are
non-zero.</p></li>
<li><p>This reflects <em>conditional</em> independencies in
data.</p></li>
<li><p>In this case <em>Markov</em> structure.</p></li>
</ul>
<h2 id="where-did-this-covariance-matrix-come-from-2">Where did this
covariance matrix come from?</h2>
<p><strong>Exponentiated Quadratic</strong></p>
<p><strong>Visualization of inverse covariance (precision).</strong></p>
<table>
<tr>
<td width="50%">
<ul>
<li>Precision matrix is not sparse.</li>
<li>Each point is dependent on all the others.</li>
<li>In this case non-Markovian.</li>
</ul>
</td>
<td width="50%">
rbfprecisionSample
</td>
</tr>
</table>
<h2 id="covariance-functions">Covariance Functions</h2>
<p><strong>Markov Process</strong></p>
<p><strong>Visualization of inverse covariance (precision).</strong></p>
<table>
<tr>
<td width="50%">
<ul>
<li>Precision matrix is sparse: only neighbours in matrix are
non-zero.</li>
<li>This reflects <em>conditional</em> independencies in data.</li>
<li>In this case <em>Markov</em> structure.</li>
</ul>
</td>
<td width="50%">
markovprecisionPlot
</td>
</tr>
</table>
<h2 id="exponential-covariance">Exponential Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/ou-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/ou-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The expontential covariance, in one dimension this is also known as
the Ornstein Uhlenbeck covariance, and in multiple dimensions it’s also
the Mater 1/2 covaraince. It has an interpretation as a stochastic
differential equation with a linear drift term (equivalent to a
quadratic potential). The drift keeps the covariance stationary (unlike
the Brownian motion covariance). It also has an interpretation as a
Cauchy filter in Fourier space <span class="citation"
data-cites="Stein:interpolation99">(Stein, 1999)</span> (from Bochner’s
theorem).</p>
<p>The covariance takes the following form, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha \exp\left(-\frac{\left\Vert
\mathbf{ x}-\mathbf{ x}^\prime \right\Vert_2}{\ell}\right)
\]</span> where <span class="math inline">\(\ell\)</span> is the
<em>length scale</em> or <em>time scale</em> of the process and <span
class="math inline">\(\alpha\)</span> represents the overall process
variance.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\exp\left(-\frac{\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2}{\ell}\right)\]</span>
</center>
<div class="figure">
<div id="ou-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/ou_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/ou_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="ou-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;ou-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ou-covariance-plot-caption" class="caption-frame">
<p>Figure: The exponential covariance function.</p>
</div>
</div>
<h2 id="basis-function-covariance">Basis Function Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/basis-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/basis-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The fixed basis function covariance just comes from the properties of
a multivariate Gaussian, if we decide <span class="math display">\[
\mathbf{ f}=\boldsymbol{ \Phi}\mathbf{ w}
\]</span> and then we assume <span class="math display">\[
\mathbf{ w}\sim \mathcal{N}\left(\mathbf{0},\alpha\mathbf{I}\right)
\]</span> then it follows from the properties of a multivariate Gaussian
that <span class="math display">\[
\mathbf{ f}\sim \mathcal{N}\left(\mathbf{0},\alpha\boldsymbol{
\Phi}\boldsymbol{ \Phi}^\top\right)
\]</span> meaning that the vector of observations from the function is
jointly distributed as a Gaussian process and the covariance matrix is
<span class="math inline">\(\mathbf{K}= \alpha\boldsymbol{
\Phi}\boldsymbol{ \Phi}^\top\)</span>, each element of the covariance
matrix can then be found as the inner product between two rows of the
basis funciton matrix.</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> basis_cov</span></code></pre></div>
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> radial</span></code></pre></div>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) =
\boldsymbol{ \phi}(\mathbf{ x})^\top \boldsymbol{ \phi}(\mathbf{
x}^\prime)\]</span>
</center>
<div class="figure">
<div id="basis-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/basis_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/basis_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="basis-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;basis-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="basis-covariance-plot-caption" class="caption-frame">
<p>Figure: A covariance function based on a non-linear basis given by
<span class="math inline">\(\boldsymbol{ \phi}(\mathbf{
x})\)</span>.</p>
</div>
</div>
<h2 id="degenerate-covariance-functions">Degenerate Covariance
Functions</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/rbf-basis-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/rbf-basis-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Any linear basis function can also be incorporated into a covariance
function. For example, an RBF network is a type of neural network with a
set of radial basis functions. Meaning, the basis funciton is radially
symmetric. These basis functions take the form, <span
class="math display">\[
\phi_k(x) = \exp\left(-\frac{\left\Vert x-\mu_k
\right\Vert_2^{2}}{\ell^{2}}\right).
\]</span> Given a set of parameters, <span class="math display">\[
\boldsymbol{ \mu}= \begin{bmatrix} -1 \\ 0 \\ 1\end{bmatrix},
\]</span> we can construct the corresponding covariance function, which
has the form, <span class="math display">\[
k\left(\mathbf{ x},\mathbf{ x}^{\prime}\right)=\alpha\boldsymbol{
\phi}(\mathbf{ x})^\top \boldsymbol{ \phi}(\mathbf{ x}^\prime).
\]</span></p>
<h2 id="bochners-theoerem">Bochners Theoerem</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/boechners-theorem.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/boechners-theorem.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p><span class="math display">\[
  Q(t) = \int_{\mathbb{R}} e^{-itx} \text{d} \mu(x).
  \]</span></p>
<p>Imagine we are given data and we wish to generalize from it. Without
making further assumptions, we have no more information than the given
data set. We can think of this ssomewhat like a weighted sum of Dirac
delta functions. The Dirac delta function is defined to be a function
with an integral of one, which is zero at all places apart from zero,
where it is infinite. Given observations at particular times (or
locations) <span class="math inline">\(\mathbf{ x}_i\)</span> we can
think of our observations as being a function, <span
class="math display">\[
f(\mathbf{ x}) = \sum_{i=1}^ny_i \delta(\mathbf{ x}-\mathbf{ x}_i),
\]</span> This function is highly discontinuous, imagine if we wished to
smooth it by filtering in Fourier space. The Fourier transform of a
function is given by, <span class="math display">\[
F(\boldsymbol{\omega}) = \int_{-\infty}^\infty f(\mathbf{ x})
\exp\left(-i2\pi \boldsymbol{\omega}^\top \mathbf{ x}\right) \text{d}
\mathbf{ x}
\]</span> and since our function is a series of delta functions the the
transform is easy to compute, <span class="math display">\[
F(\boldsymbol{\omega}) = \sum_{i=1}^ny_i\exp\left(-i 2\pi
\boldsymbol{\omega}^\top \mathbf{ x}_i\right)
\]</span> which has a real part given by a weighted sum of cosines and a
complex part given by a weighted sum of sines.</p>
<p>One theorem that gives insight into covariances is Bochner’s theorem.
Bochner’s theorem states that any positive filter in Fourier space gives
rise to a valid covariance function. Further, it gives a relationship
between the filter and the form of the covariance function. The form of
the covariance is given by the <a
href="http://en.wikipedia.org/wiki/Fourier_transform">Fourier
transform</a> of the filter, with the argument of the transform being
replaced by the distance between the points.</p>
<p>Fourier space is a transformed space of the original function to a
new basis. The transformation occurs through a convolution with a sine
and cosine basis. Given a function of time <span
class="math inline">\(f(t)\)</span> the Fourier transform moves it to a
weighted linear sum of a sine and cosine basis, <span
class="math display">\[
F(\omega) = \int_{-\infty}^\infty f(t) \left[\cos(2\pi \omega t) - i
\sin(2\pi \omega t) \right]\text{d} t
\]</span> where is the imaginary basis, <span
class="math inline">\(i=\sqrt{-1}\)</span>. Through Euler’s formula,
<span class="math display">\[
\exp(ix) = \cos x + i\sin x
\]</span> we can re-express this form as <span class="math display">\[
F(\omega) = \int_{-\infty}^\infty f(t) \exp(-i 2\pi\omega)\text{d} t
\]</span> which is a standard form for the Fourier transform. Fourier’s
theorem was that the <em>inverse</em> transform can also be expressed in
a similar form so we have <span class="math display">\[
f(t) = \int_{-\infty}^\infty F(\omega) \exp(2\pi\omega)\text{d} \omega.
\]</span> Although we’ve introduced the transform in the context of time
Fourier’s interest was an analytical theory of heat and the transform
can be applied to a multidimensional spatial function, <span
class="math inline">\(f(\mathbf{ x})\)</span>.</p>
<iframe frameborder="0" scrolling="no" style="border:0px" src="https://books.google.co.uk/books?id=TDQJAAAAIAAJ&amp;pg=PA525&amp;output=embed" width="700" height="500">
</iframe>
<h2 id="sinc-covariance">Sinc Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/sinc-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/sinc-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Another approach to developing covariance function exploits Bochner’s
theorem <span class="citation" data-cites="Bochner:book59">Bochner
(1959)</span>. Bochner’s theorem tells us that any positve filter in
Fourier space implies has an associated Gaussian process with a
stationary covariance function. The covariance function is the
<em>inverse Fourier transform</em> of the filter applied in Fourier
space.</p>
<p>For example, in signal processing, <em>band limitations</em> are
commonly applied as an assumption. For example, we may believe that no
frequency above <span class="math inline">\(w=2\)</span> exists in the
signal. This is equivalent to a rectangle function being applied as a
the filter in Fourier space.</p>
<p>The inverse Fourier transform of the rectangle function is the <span
class="math inline">\(\text{sinc}(\cdot)\)</span> function. So the sinc
is a valid covariance function, and it represents <em>band limited</em>
signals.</p>
<p>Note that other covariance functions we’ve introduced can also be
interpreted in this way. For example, the exponentiated quadratic
covariance function can be Fourier transformed to see what the implied
filter in Fourier space is. The Fourier transform of the exponentiated
quadratic is an exponentiated quadratic, so the standard EQ-covariance
implies a EQ filter in Fourier space.</p>
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> sinc_cov</span></code></pre></div>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\text{sinc}\left(\pi w r\right)\]</span>
</center>
<div class="figure">
<div id="sinc-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/sinc_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/sinc_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="sinc-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;sinc-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="sinc-covariance-plot-caption" class="caption-frame">
<p>Figure: Sinc covariance function.</p>
</div>
</div>
<h2 id="matérn-32-covariance">Matérn 3/2 Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/matern32-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/matern32-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Matérn 3/2 <span class="citation"
data-cites="Stein:interpolation99">(Stein, 1999)</span> covariance is
which is once differentiable, it arises from applying a Student-<span
class="math inline">\(t\)</span> based filter in Fourier space with
three degrees of freedom.</p>
<p>The covariance takes the following form, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\left(1+\frac{\sqrt{3}\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2}{\ell}\right)\exp\left(-\frac{\sqrt{3}\left\Vert \mathbf{
x}-\mathbf{ x}^\prime \right\Vert_2}{\ell}\right)
\]</span> where <span class="math inline">\(\ell\)</span> is the
<em>length scale</em> or <em>time scale</em> of the process and <span
class="math inline">\(\alpha\)</span> represents the overall process
variance.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\left(1+\frac{\sqrt{3}\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2}{\ell}\right)\exp\left(-\frac{\sqrt{3}\left\Vert \mathbf{
x}-\mathbf{ x}^\prime \right\Vert_2}{\ell}\right)\]</span>
</center>
<div class="figure">
<div id="matern32-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/matern32_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/matern32_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="matern32-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;matern32-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="matern32-covariance-plot-caption" class="caption-frame">
<p>Figure: The Matérn 3/2 covariance function.</p>
</div>
</div>
<h2 id="matérn-52-covariance">Matérn 5/2 Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/matern52-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/matern52-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Matérn 5/2 <span class="citation"
data-cites="Stein:interpolation99">(Stein, 1999)</span> covariance is
which is once differentiable, it arises from applying a Student-<span
class="math inline">\(t\)</span> based filter in Fourier space with five
degrees of freedom.</p>
<p>The covariance takes the following form, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\left(1+\frac{\sqrt{5}\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2}{\ell} + \frac{5\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2^2}{3\ell^2}\right)\exp\left(-\frac{\sqrt{5}\left\Vert
\mathbf{ x}-\mathbf{ x}^\prime \right\Vert_2}{\ell}\right)
\]</span> where <span class="math inline">\(\ell\)</span> is the
<em>length scale</em> or <em>time scale</em> of the process and <span
class="math inline">\(\alpha\)</span> represents the overall process
variance.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\left(1+\frac{\sqrt{5}\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2}{\ell} + \frac{5\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2^2}{3\ell^2}\right)\exp\left(-\frac{\sqrt{5}\left\Vert
\mathbf{ x}-\mathbf{ x}^\prime \right\Vert_2}{\ell}\right)\]</span>
</center>
<div class="figure">
<div id="matern52-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/matern52_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/matern52_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="matern52-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;matern52-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="matern52-covariance-plot-caption" class="caption-frame">
<p>Figure: The Matérn 5/2 covariance function.</p>
</div>
</div>
<h2 id="rational-quadratic-covariance">Rational Quadratic
Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/ratquad-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/ratquad-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The rational quadratic covariance function is derived by a continuous
mixture of exponentiated quadratic covariance funcitons, where the
lengthscale is given by an inverse gamma distribution. The resulting
covariance is infinitely smooth (in terms of differentiability) but has
a family of length scales present. As <span
class="math inline">\(a\)</span> gets larger, the exponentiated
quadratic covariance funciton is recovered.</p>
<p>The covariance takes the following form, <span
class="math display">\[
k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha \left(1+\frac{\left\Vert
\mathbf{ x}-\mathbf{ x}^\prime \right\Vert_2^2}{2 a \ell^2}\right)^{-a}
\]</span> where <span class="math inline">\(\ell\)</span> is the
<em>length scale</em> or <em>time scale</em> of the process and <span
class="math inline">\(\alpha\)</span> represents the overall process
variance and <span class="math inline">\(a\)</span> represents shape
parameter of the inverse Gamma used to create the scale mixture.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\left(1+\frac{\left\Vert \mathbf{ x}-\mathbf{ x}^\prime
\right\Vert_2^2}{2 a \ell^2}\right)^{-a}\]</span>
</center>
<div class="figure">
<div id="ratquad-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/ratquad_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/ratquad_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="ratquad-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;ratquad-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="ratquad-covariance-plot-caption" class="caption-frame">
<p>Figure: The rational quadratic covariance function.</p>
</div>
</div>
<h2 id="polynomial-covariance">Polynomial Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/poly-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/poly-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) =
\alpha(w \mathbf{ x}^\top\mathbf{ x}^\prime + b)^d\]</span>
</center>
<div class="figure">
<div id="polynomial-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/polynomial_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/polynomial_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="polynomial-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;polynomial-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="polynomial-covariance-plot-caption" class="caption-frame">
<p>Figure: Polynomial covariance function.</p>
</div>
</div>
<h2 id="periodic-covariance">Periodic Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/periodic-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/periodic-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) =
\alpha\exp\left(\frac{-2\sin(\pi rw)^2}{\ell^2}\right)\]</span>
</center>
<div class="figure">
<div id="periodic-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/periodic_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/periodic_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="periodic-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;periodic-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="periodic-covariance-plot-caption" class="caption-frame">
<p>Figure: Periodic covariance function.</p>
</div>
</div>
<h2 id="mlp-covariance">MLP Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/mlp-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/mlp-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> mlp_cov</span></code></pre></div>
<p>The multi-layer perceptron (MLP) covariance, also known as the neural
network covariance or the arcsin covariance, is derived by considering
the infinite limit of a neural network.</p>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) = \alpha
\arcsin\left(\frac{w \mathbf{ x}^\top \mathbf{ x}^\prime +
b}{\sqrt{\left(w \mathbf{ x}^\top \mathbf{ x}+ b + 1\right)\left(w
\left.\mathbf{ x}^\prime\right.^\top \mathbf{ x}^\prime + b +
1\right)}}\right)\]</span>
</center>
<div class="figure">
<div id="mlp-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/mlp_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/mlp_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="mlp-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;mlp-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mlp-covariance-plot-caption" class="caption-frame">
<p>Figure: The multi-layer perceptron covariance function. This is
derived by considering the infinite limit of a neural network with
probit activation functions.</p>
</div>
</div>
<h2 id="relu-covariance">RELU Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/relu-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/relu-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlai</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> mlai <span class="im">import</span> relu_cov</span></code></pre></div>
<center>
<span class="math display">\[k(\mathbf{ x}, \mathbf{ x}^\prime) =
\alpha \arcsin\left(\frac{w \mathbf{ x}^\top \mathbf{ x}^\prime + b}
{\sqrt{\left(w \mathbf{ x}^\top \mathbf{ x}+ b + 1\right)
\left(w \left.\mathbf{ x}^\prime\right.^\top \mathbf{ x}^\prime + b +
1\right)}}\right)\]</span>
</center>
<div class="figure">
<div id="relu-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/relu_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/relu_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="relu-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;relu-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="relu-covariance-plot-caption" class="caption-frame">
<p>Figure: Rectified linear unit covariance function.</p>
</div>
</div>
<h2 id="additive-covariance">Additive Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/add-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/add-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>An additive covariance function is derived from considering the
result of summing two Gaussian processes together. If the first Gaussian
process is <span class="math inline">\(g(\cdot)\)</span>, governed by
covariance <span class="math inline">\(k_g(\cdot, \cdot)\)</span> and
the second process is <span class="math inline">\(h(\cdot)\)</span>,
governed by covariance <span class="math inline">\(k_h(\cdot,
\cdot)\)</span> then the combined process <span
class="math inline">\(f(\cdot) = g(\cdot) + h(\cdot)\)</span> is
govererned by a covariance function, <span class="math display">\[
k_f(\mathbf{ x}, \mathbf{ x}^\prime) = k_g(\mathbf{ x}, \mathbf{
x}^\prime) + k_h(\mathbf{ x}, \mathbf{ x}^\prime)
\]</span></p>
<center>
<span class="math display">\[k_f(\mathbf{ x}, \mathbf{ x}^\prime) =
k_g(\mathbf{ x}, \mathbf{ x}^\prime) + k_h(\mathbf{ x}, \mathbf{
x}^\prime)\]</span>
</center>
<div class="figure">
<div id="add-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/add_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/add_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="add-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;add-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="add-covariance-plot-caption" class="caption-frame">
<p>Figure: An additive covariance function formed by combining a linear
and an exponentiated quadratic covariance functions.</p>
</div>
</div>
<h2 id="product-covariance">Product Covariance</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/prod-covariance.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/prod-covariance.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>An product covariance function is derived from considering the result
of multiplying two stochastic processes together. If the first
stochastic process is <span class="math inline">\(g(\cdot)\)</span>,
governed by covariance <span class="math inline">\(k_g(\cdot,
\cdot)\)</span> and the second process is <span
class="math inline">\(h(\cdot)\)</span>, governed by covariance <span
class="math inline">\(k_h(\cdot, \cdot)\)</span> then the combined
process <span class="math inline">\(f(\cdot) = g(\cdot)
h(\cdot)\)</span> is governed by a covariance function, <span
class="math display">\[
k_f(\mathbf{ x}, \mathbf{ x}^\prime) = k_g(\mathbf{ x}, \mathbf{
x}^\prime) k_h(\mathbf{ x}, \mathbf{ x}^\prime)
\]</span> Note that if <span class="math inline">\(g(\cdot)\)</span> and
<span class="math inline">\(h(\cdot)\)</span> are Gaussian processes
then <span class="math inline">\(f(\cdot)\)</span> will not in general
be a Gaussian process. So the base processes are (presumably) some
(unspecified) non-Gaussian processes.</p>
<center>
<span class="math display">\[k_f(\mathbf{ x}, \mathbf{ x}^\prime) =
k_g(\mathbf{ x}, \mathbf{ x}^\prime) k_h(\mathbf{ x}, \mathbf{
x}^\prime)\]</span>
</center>
<div class="figure">
<div id="prod-covariance-plot-figure" class="figure-frame">
<table>
<tr>
<td width="45%">
<object class data="../slides/diagrams/kern/prod_covariance.svg" width="100%" style=" ">
</object>
</td>
<td width="45%">
<div class="centered" style="">
<img class="negate" src="../slides/diagrams/kern/prod_covariance.gif" width="100%" height="auto" align="center" style="background:none; border:none; box-shadow:none; display:block; margin-left:auto; margin-right:auto;vertical-align:middle">
</div>
</td>
</tr>
</table>
</div>
<div id="prod-covariance-plot-magnify" class="magnify"
onclick="magnifyFigure(&#39;prod-covariance-plot&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="prod-covariance-plot-caption" class="caption-frame">
<p>Figure: An product covariance function formed by combining a linear
and an exponentiated quadratic covariance functions.</p>
</div>
</div>
<h2 id="mauna-loa-data">Mauna Loa Data</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_datasets/includes/mauna-loa-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/mauna-loa-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The Mauna Loa data consists of monthly mean carbon dioxide measured
at Mauna Loa Observatory, Hawaii. According to the website, <a
href="https://www.esrl.noaa.gov/gmd/ccgg/trends/"
class="uri">https://www.esrl.noaa.gov/gmd/ccgg/trends/</a>.</p>
<blockquote>
<p>The carbon dioxide data on Mauna Loa constitute the longest record of
direct measurements of CO2 in the atmosphere. They were started by C.
David Keeling of the Scripps Institution of Oceanography in March of
1958 at a facility of the National Oceanic and Atmospheric
Administration <span class="citation"
data-cites="Keeling-atmospheric76">(Keeling et al., 1976)</span>. NOAA
started its own CO2 measurements in May of 1974, and they have run in
parallel with those made by Scripps since then <span class="citation"
data-cites="Thoning-atmospheric89">(Thoning et al., 1989)</span>.</p>
</blockquote>
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>pip install pods</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.mauna_loa()</span></code></pre></div>
<p>Here, if you’ve downloaded the data before you have a cached version.
To download a fresh version of the data I can set
<code>refresh_data=True</code>.</p>
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.mauna_loa(refresh_data<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>offset <span class="op">=</span> y.mean()</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> np.sqrt(y.var())</span></code></pre></div>
<p>The data dictionary contains the standard keys ‘X’ and ‘Y’ which give
a unidimensional regression problem.</p>
<div class="figure">
<div id="mauna-loa-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//datasets/mauna-loa.svg" width="80%" style=" ">
</object>
</div>
<div id="mauna-loa-magnify" class="magnify"
onclick="magnifyFigure(&#39;mauna-loa&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mauna-loa-caption" class="caption-frame">
<p>Figure: Mauna Loa data shows carbon dioxide monthly average
measurements from the Mauna Loa Observatory in Hawaii.</p>
</div>
</div>
<p>Additionally there are keys <code>Xtest</code> and <code>Ytest</code>
which provide test data. The number of points considered to be
<em>training data</em> is controlled by the argument
<code>num_train</code> argument, which defaults to 545. This number is
chosen as it matches that used in the <a
href="http://www.gaussianprocess.org/gpml/chapters/RW5.pdf">Gaussian
Processes for Machine Learning</a> book <span class="citation"
data-cites="Rasmussen:book06">(Rasmussen and Williams, 2006, chap.
5)</span>. Below we plot the test and training data.</p>
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>xtest <span class="op">=</span> data[<span class="st">&#39;Xtest&#39;</span>]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>ytest <span class="op">=</span> data[<span class="st">&#39;Ytest&#39;</span>]</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>ytesthat <span class="op">=</span> (ytest<span class="op">-</span>offset)<span class="op">/</span>scale</span></code></pre></div>
<div class="figure">
<div id="mauna-loa-test-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//datasets/mauna-loa-test.svg" width="80%" style=" ">
</object>
</div>
<div id="mauna-loa-test-magnify" class="magnify"
onclick="magnifyFigure(&#39;mauna-loa-test&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mauna-loa-test-caption" class="caption-frame">
<p>Figure: Mauna Loa test data shows carbon dioxide monthly average
measurements from the Mauna Loa Observatory in Hawaii.</p>
</div>
</div>
<p>Of course we have included the citation information for the data.</p>
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&#39;citation&#39;</span>])</span></code></pre></div>
<p>And extra information about the data is included, as standard, under
the keys <code>info</code> and <code>details</code>.</p>
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&#39;info&#39;</span>])</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>()</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&#39;details&#39;</span>])</span></code></pre></div>
<p>And, importantly, for reference you can also check the license for
the data:</p>
<div class="sourceCode" id="cb24"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&#39;license&#39;</span>])</span></code></pre></div>
<h2 id="gaussian-process-fit">Gaussian Process Fit</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/mauna-loa-gp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/mauna-loa-gp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>The data set was used as a demonstration of model selection for
Gaussian processes in <span class="citation"
data-cites="Rasmussen:book06">Rasmussen and Williams (2006)</span>
(Chapter 5).</p>
<p>Here we reconstruct that analysis in GPy. Our first objective will be
to perform a Gaussian process fit to the data, we’ll do this using the
<a href="https://github.com/SheffieldML/GPy">GPy software</a>.</p>
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb26"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>kernel1 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="dv">40</span>, variance<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>kernel2 <span class="op">=</span> GPy.kern.PeriodicMatern52(<span class="dv">1</span>, variance<span class="op">=</span><span class="dv">4</span>, period<span class="op">=</span><span class="dv">1</span>, lengthscale<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>kernel3 <span class="op">=</span> GPy.kern.RatQuad(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="dv">5</span>, variance<span class="op">=</span><span class="dv">10</span>, power<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>kernel4 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="fl">0.2</span>, variance<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>kernel5 <span class="op">=</span> GPy.kern.Bias(<span class="dv">1</span>, variance<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> kernel1 <span class="op">+</span> kernel2 <span class="op">+</span> kernel3 <span class="op">+</span> kernel4 <span class="op">+</span> kernel5</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(x,yhat, kernel<span class="op">=</span>kernel)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>) <span class="co"># Optimize parameters of covariance function</span></span></code></pre></div>
<p>The first command sets up the model, then
<code>model.optimize()</code> optimizes the parameters of the covariance
function and the noise level of the model. Once the fit is complete,
we’ll try creating some test points, and computing the output of the GP
model in terms of the mean and standard deviation of the posterior
functions between 1870 and 2030. We plot the mean function and the
standard deviation at 200 locations. We can obtain the predictions using
<code>y_mean, y_var = model.predict(xt)</code></p>
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> np.linspace(xlim[<span class="dv">0</span>],xlim[<span class="dv">1</span>],<span class="dv">300</span>)[:,np.newaxis]</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>yt_mean, yt_var <span class="op">=</span> model.predict(xt)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>yt_sd<span class="op">=</span>np.sqrt(yt_var)</span></code></pre></div>
<p>Now we plot the results using the helper function in
<code>mlai.plot</code>.</p>
<div class="figure">
<div id="mauna-loa-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/mauna-loa-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="mauna-loa-gp-magnify" class="magnify"
onclick="magnifyFigure(&#39;mauna-loa-gp&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mauna-loa-gp-caption" class="caption-frame">
<p>Figure: Gaussian process fit to the Mauna Loa Observatory data on CO2
concentrations.</p>
</div>
</div>
<h2 id="box-jenkins-airline-passenger-data">Box Jenkins Airline
Passenger Data</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_datasets/includes/box-jenkins-airline-data.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/box-jenkins-airline-data.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>This data is giving airline passenger numbers between 1948 and 1960.
It was published by <span class="citation"
data-cites="Box-timeseries76">Box and Jenkins (1976)</span>.</p>
<div class="sourceCode" id="cb28"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.boxjenkins_airline()</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>xtest <span class="op">=</span> data[<span class="st">&#39;Xtest&#39;</span>]</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>ytest <span class="op">=</span> data[<span class="st">&#39;Ytest&#39;</span>]</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>offset <span class="op">=</span> y.mean()</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>scale <span class="op">=</span> np.sqrt(y.var())</span></code></pre></div>
<div class="figure">
<div id="box-jenkins-airline-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//datasets/box-jenkins-airline.svg" width="80%" style=" ">
</object>
</div>
<div id="box-jenkins-airline-magnify" class="magnify"
onclick="magnifyFigure(&#39;box-jenkins-airline&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="box-jenkins-airline-caption" class="caption-frame">
<p>Figure: Box-Jenkins data set on airline passenger numbers.</p>
</div>
</div>
<h2 id="gaussian-process-fit-1">Gaussian Process Fit</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_gp/includes/box-jenkins-airline-gp.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/box-jenkins-airline-gp.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<p>Here we reconstruct that analysis in GPy. Our first objective will be
to perform a Gaussian process fit to the data, we’ll do this using the
<a href="https://github.com/SheffieldML/GPy">GPy software</a>.</p>
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>kernel1 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="dv">40</span>, variance<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>kernel2 <span class="op">=</span> GPy.kern.PeriodicMatern52(<span class="dv">1</span>, variance<span class="op">=</span><span class="dv">4</span>, period<span class="op">=</span><span class="dv">1</span>, lengthscale<span class="op">=</span><span class="fl">0.2</span>)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>kernel3 <span class="op">=</span> GPy.kern.RatQuad(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="dv">5</span>, variance<span class="op">=</span><span class="dv">10</span>, power<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>kernel4 <span class="op">=</span> GPy.kern.RBF(<span class="dv">1</span>, lengthscale<span class="op">=</span><span class="fl">0.2</span>, variance<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>kernel5 <span class="op">=</span> GPy.kern.Bias(<span class="dv">1</span>, variance<span class="op">=</span><span class="dv">100</span>)</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> kernel1 <span class="op">+</span> kernel2 <span class="op">+</span> kernel3 <span class="op">+</span> kernel4 <span class="op">+</span> kernel5</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(x,yhat, kernel<span class="op">=</span>kernel)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>) <span class="co"># Optimize parameters of covariance function</span></span></code></pre></div>
<p>The first command sets up the model, then
<code>model.optimize()</code> optimizes the parameters of the covariance
function and the noise level of the model. Once the fit is complete,
we’ll try creating some test points, and computing the output of the GP
model in terms of the mean and standard deviation of the posterior
functions between 1948 and 1958. We plot the mean function and the
standard deviation at 200 locations. We can obtain the predictions using
<code>y_mean, y_var = model.predict(xt)</code></p>
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>xt <span class="op">=</span> np.linspace(xlim[<span class="dv">0</span>],xlim[<span class="dv">1</span>],<span class="dv">300</span>)[:,np.newaxis]</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>yt_mean, yt_var <span class="op">=</span> model.predict(xt)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>yt_sd<span class="op">=</span>np.sqrt(yt_var)</span></code></pre></div>
<p>Now we plot the results using the helper function in
<code>mlai.plot</code>.</p>
<div class="figure">
<div id="box-jenkins-airline-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/box-jenkins-airline-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="box-jenkins-airline-gp-magnify" class="magnify"
onclick="magnifyFigure(&#39;box-jenkins-airline-gp&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="box-jenkins-airline-gp-caption" class="caption-frame">
<p>Figure: Gaussian process fit to the Box-Jenkins airline passenger
data.</p>
</div>
</div>
<h2 id="spectral-mixture-kernel">Spectral Mixture Kernel</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/spectral-mixture-kernel.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/spectral-mixture-kernel.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<h2 id="box-jenkins-airline-spectral-mixture">Box-Jenkins Airline
Spectral Mixture</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/box-jenkins-airline-spectral-mixture.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/box-jenkins-airline-spectral-mixture.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.boxjenkins_airline()</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb36"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>num_comps <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> GPy.kern.ExpQuadCosine(<span class="dv">1</span>)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_comps<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">+=</span> GPy.kern.ExpQuadCosine(<span class="dv">1</span>)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>kernel<span class="op">+=</span>GPy.kern.Bias(<span class="dv">1</span>)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>kernel.randomize()</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(x, y, kernel)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*lengthscale&#39;] = np.random.uniform(0.0, 6.0, size=model[&#39;.*lengthscale&#39;].shape)</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*bandwidth&#39;] = 2./np.sqrt(np.random.gamma(1.0, 0.5*(X.max()-X.min()), size=model[&#39;.*bandwidth&#39;].shape))</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*variance&#39;] = 5.0</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<div class="figure">
<div id="box-jenkins-spectral-mixture-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/box-jenkins-spectral-mixture-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="box-jenkins-spectral-mixture-gp-magnify" class="magnify"
onclick="magnifyFigure(&#39;box-jenkins-spectral-mixture-gp&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="box-jenkins-spectral-mixture-gp-caption" class="caption-frame">
<p>Figure: Spectral mixture GP as applied to the Box-Jenkins airline
data.</p>
</div>
</div>
<h2 id="mauna-loa-spectral-mixture">Mauna Loa Spectral Mixture</h2>
<div style="text-align:right">
<span class="editsection-bracket" style="">[</span><span
class="editsection"
style=""><a href="https://github.com/lawrennd/snippets/edit/main/_kern/includes/mauna-loa-spectral-mixture.md" target="_blank" onclick="ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/mauna-loa-spectral-mixture.md', 13);">edit</a></span><span class="editsection-bracket" style="">]</span>
</div>
<div class="sourceCode" id="cb39"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pods</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pods.datasets.mauna_loa()</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> data[<span class="st">&#39;X&#39;</span>]</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">&#39;Y&#39;</span>]</span></code></pre></div>
<div class="sourceCode" id="cb41"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> GPy</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>num_comps <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> GPy.kern.ExpQuadCosine(<span class="dv">1</span>)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(num_comps<span class="op">-</span><span class="dv">1</span>):</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    kernel <span class="op">+=</span> GPy.kern.ExpQuadCosine(<span class="dv">1</span>)</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>kernel<span class="op">+=</span>GPy.kern.Bias(<span class="dv">1</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>kernel.randomize()</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> GPy.models.GPRegression(x, y, kernel)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*frequency&#39;] = np.random.uniform(0.0, 6.0, size=model[&#39;.*frequency&#39;].shape)</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*bandwidth&#39;] = 2./np.sqrt(np.random.gamma(1.0, 0.5*(X.max()-X.min()), size=model[&#39;.*bandwidth&#39;].shape))</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*variance&#39;] = 5.0</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">#model[&#39;.*bias_variance&#39;] = 90000</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<p>Now we optimize the model.</p>
<div class="sourceCode" id="cb43"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model.optimize(messages<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
<div class="sourceCode" id="cb44"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>display(model)</span></code></pre></div>
<div class="figure">
<div id="mauna-loa-spectral-mixture-gp-figure" class="figure-frame">
<object class="svgplot " data="https://mlatcl.github.io/gpss/./slides/diagrams//gp/mauna-loa-spectral-mixture-gp.svg" width="80%" style=" ">
</object>
</div>
<div id="mauna-loa-spectral-mixture-gp-magnify" class="magnify"
onclick="magnifyFigure(&#39;mauna-loa-spectral-mixture-gp&#39;)">
<img class="img-button" src="{{ '/assets/images/Magnify_Large.svg' | relative_url }}" style="width:1.5ex">
</div>
<div id="mauna-loa-spectral-mixture-gp-caption" class="caption-frame">
<p>Figure: Spectral mixture GP as applied to the Mauna Loa Observatory
carbon dioxide concentration data.</p>
</div>
</div>
<h2 id="thanks">Thanks!</h2>
<p>For more information on these subjects and more you might want to
check the following resources.</p>
<ul>
<li>twitter: <a href="https://twitter.com/lawrennd">@lawrennd</a></li>
<li>podcast: <a href="http://thetalkingmachines.com">The Talking
Machines</a></li>
<li>newspaper: <a
href="http://www.theguardian.com/profile/neil-lawrence">Guardian Profile
Page</a></li>
<li>blog: <a
href="http://inverseprobability.com/blog.html">http://inverseprobability.com</a></li>
</ul>
<h1 class="unnumbered" id="references">References</h1>
<div id="refs" class="references csl-bib-body hanging-indent"
role="list">
<div id="ref-Bochner:book59" class="csl-entry" role="listitem">
Bochner, S., 1959. <a
href="http://books.google.co.uk/books?id=-vU02QewWK8C">Lectures on
<span>F</span>ourier integrals</a>. Princeton University Press.
</div>
<div id="ref-Box-timeseries76" class="csl-entry" role="listitem">
Box, G.E.P., Jenkins, G.M., 1976. Time series analysis: Forecasting and
control. Holden-Day.
</div>
<div id="ref-Keeling-atmospheric76" class="csl-entry" role="listitem">
Keeling, C.D., Bacastow, R.B., Bainbridge, A.E., Ekdahl Jr., C.A.,
Guenther, P.R., Waterman, L.S., Chin, J.F.S., 1976. Atmospheric carbon
dioxide variations at <span>M</span>auna <span>L</span>oa
<span>O</span>bservatory, <span>H</span>awaii. Tellus 28, 538–551. <a
href="https://doi.org/10.1111/j.2153-3490.1976.tb00701.x">https://doi.org/10.1111/j.2153-3490.1976.tb00701.x</a>
</div>
<div id="ref-Rasmussen:book06" class="csl-entry" role="listitem">
Rasmussen, C.E., Williams, C.K.I., 2006. Gaussian processes for machine
learning. mit, Cambridge, MA.
</div>
<div id="ref-Stein:interpolation99" class="csl-entry" role="listitem">
Stein, M.L., 1999. Interpolation of spatial data: Some theory for
<span>K</span>riging. springer.
</div>
<div id="ref-Thoning-atmospheric89" class="csl-entry" role="listitem">
Thoning, K.W., Tans, P.P., Komhyr, W.D., 1989. Atmospheric carbon
dioxide at <span>M</span>auna <span>L</span>oa <span>O</span>bservatory:
2. <span>A</span>nalysis of the <span>NOAA</span> <span>GMCC</span>
data, 1974–1985. Journal of Geophysical Research: Atmospheres 94,
8549–8565. <a
href="https://doi.org/10.1029/JD094iD06p08549">https://doi.org/10.1029/JD094iD06p08549</a>
</div>
</div>

