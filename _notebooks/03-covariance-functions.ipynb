{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covariance Functions and Hyperparameter Optimization\n",
    "\n",
    "### Neil D. Lawrence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Abstract**: In this talk we review covariance functions and\n",
    "optimization of the GP log likelihoood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.cell .markdown}\n",
    "\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!---->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- Do not edit this file locally. -->\n",
    "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
    "<!--\n",
    "\n",
    "-->\n",
    "<!-- To compile -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPy: A Gaussian Process Framework in Python\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/gpy-software.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_software/includes/gpy-software.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Gaussian processes are a flexible tool for non-parametric analysis with\n",
    "uncertainty. The GPy software was started in Sheffield to provide a easy\n",
    "to use interface to GPs. One which allowed the user to focus on the\n",
    "modelling rather than the mathematics.\n",
    "\n",
    "<img class=\"\" src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gpy.png\" style=\"width:70%\">\n",
    "\n",
    "Figure: <i>GPy is a BSD licensed software code base for implementing\n",
    "Gaussian process models in Python. It is designed for teaching and\n",
    "modelling. We welcome contributions which can be made through the GitHub\n",
    "repository <https://github.com/SheffieldML/GPy></i>\n",
    "\n",
    "GPy is a BSD licensed software code base for implementing Gaussian\n",
    "process models in python. This allows GPs to be combined with a wide\n",
    "variety of software libraries.\n",
    "\n",
    "The software itself is available on\n",
    "[GitHub](https://github.com/SheffieldML/GPy) and the team welcomes\n",
    "contributions.\n",
    "\n",
    "The aim for GPy is to be a probabilistic-style programming language,\n",
    "i.e., you specify the model rather than the algorithm. As well as a\n",
    "large range of covariance functions the software allows for non-Gaussian\n",
    "likelihoods, multivariate outputs, dimensionality reduction and\n",
    "approximations for larger data sets.\n",
    "\n",
    "The documentation for GPy can be found\n",
    "[here](https://gpy.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of the Covariance Function\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-covariance-function-importance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-covariance-function-importance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The covariance function encapsulates our assumptions about the data. The\n",
    "equations for the distribution of the prediction function, given the\n",
    "training observations, are highly sensitive to the covariation between\n",
    "the test locations and the training locations as expressed by the matrix\n",
    "$\\mathbf{K}_*$. We defined a matrix $\\mathbf{A}$ which allowed us to\n",
    "express our conditional mean in the form, $$\n",
    "\\boldsymbol{ \\mu}_f= \\mathbf{A}^\\top \\mathbf{ y},\n",
    "$$ where $\\mathbf{ y}$ were our *training observations*. In other words\n",
    "our mean predictions are always a linear weighted combination of our\n",
    "*training data*. The weights are given by computing the covariation\n",
    "between the training and the test data ($\\mathbf{K}_*$) and scaling it\n",
    "by the inverse covariance of the training data observations,\n",
    "$\\left[\\mathbf{K}+ \\sigma^2 \\mathbf{I}\\right]^{-1}$. This inverse is the\n",
    "main computational object that needs to be resolved for a Gaussian\n",
    "process. It has a computational burden which is $O(n^3)$ and a storage\n",
    "burden which is $O(n^2)$. This makes working with Gaussian processes\n",
    "computationally intensive for the situation where $n>10,000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "YouTubeVideo('ewJ3AxKclOg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure: <i>Introduction to Gaussian processes given by Neil Lawrence at\n",
    "the 2014 Gaussian process Winter School at the University of\n",
    "Sheffield.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the Numerics\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-numerics-and-optimization.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-numerics-and-optimization.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "In practice we shouldn’t be using matrix inverse directly to solve the\n",
    "GP system. One more stable way is to compute the *Cholesky\n",
    "decomposition* of the kernel matrix. The log determinant of the\n",
    "covariance can also be derived from the Cholesky decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.update_inverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GP.update_inverse = update_inverse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Control\n",
    "\n",
    "Gaussian processes are sometimes seen as part of a wider family of\n",
    "methods known as kernel methods. Kernel methods are also based around\n",
    "covariance functions, but in the field they are known as Mercer kernels.\n",
    "Mercer kernels have interpretations as inner products in potentially\n",
    "infinite dimensional Hilbert spaces. This interpretation arises because,\n",
    "if we take $\\alpha=1$, then the kernel can be expressed as $$\n",
    "\\mathbf{K}= \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top \n",
    "$$ which imples the elements of the kernel are given by, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\boldsymbol{ \\phi}(\\mathbf{ x})^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}^\\prime).\n",
    "$$ So we see that the kernel function is developed from an inner product\n",
    "between the basis functions. Mercer’s theorem tells us that any valid\n",
    "*positive definite function* can be expressed as this inner product but\n",
    "with the caveat that the inner product could be *infinite length*. This\n",
    "idea has been used quite widely to *kernelize* algorithms that depend on\n",
    "inner products. The kernel functions are equivalent to covariance\n",
    "functions and they are parameterized accordingly. In the kernel modeling\n",
    "community it is generally accepted that kernel parameter estimation is a\n",
    "difficult problem and the normal solution is to cross validate to obtain\n",
    "parameters. This can cause difficulties when a large number of kernel\n",
    "parameters need to be estimated. In Gaussian process modelling kernel\n",
    "parameter estimation (in the simplest case proceeds) by maximum\n",
    "likelihood. This involves taking gradients of the likelihood with\n",
    "respect to the parameters of the covariance function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradients of the Likelihood\n",
    "\n",
    "The easiest conceptual way to obtain the gradients is a two step\n",
    "process. The first step involves taking the gradient of the likelihood\n",
    "with respect to the covariance function, the second step involves\n",
    "considering the gradient of the covariance function with respect to its\n",
    "parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Process Scale\n",
    "\n",
    "In general we won’t be able to find parameters of the covariance\n",
    "function through fixed point equations, we will need to do gradient\n",
    "based optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Control and Data Fit\n",
    "\n",
    "The objective function can be decomposed into two terms, a capacity\n",
    "control term, and a data fit term. The capacity control term is the log\n",
    "determinant of the covariance. The data fit term is the matrix inner\n",
    "product between the data and the inverse covariance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateObject(rotationMatrix, handle):\n",
    "for i = 1:prod(size(handle))\n",
    "    type = get(handle(i), 'type');\n",
    "    if strcmp(type, 'text'):\n",
    "        xy = get(handle(i), 'position');\n",
    "        xy(1:2) = rotationMatrix*xy(1:2)';\n",
    "        set(handle(i), 'position', xy);\n",
    "    else:\n",
    "        xd = get(handle(i), 'xdata');\n",
    "        yd = get(handle(i), 'ydata');\n",
    "        new = rotationMatrix*[xd(:)'; yd(:)'];\n",
    "        set(handle(i), 'xdata', new(1, :));\n",
    "        set(handle(i), 'ydata', new(2, :));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Covariance Parameters\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Can we determine covariance parameters from the data?\n",
    "\n",
    "$$\n",
    "\\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=\\frac{1}{(2\\pi)^\\frac{n}{2}{\\det{\\mathbf{K}}^{\\frac{1}{2}}}}{\\exp\\left(-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=\\frac{1}{(2\\pi)^\\frac{n}{2}\\color{blue}{\\det{\\mathbf{K}}^{\\frac{1}{2}}}}\\color{red}{\\exp\\left(-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}\\right)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\log \\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=&\\color{blue}{-\\frac{1}{2}\\log\\det{\\mathbf{K}}}\\color{red}{-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}} \\\\ &-\\frac{n}{2}\\log2\\pi\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "E(\\boldsymbol{ \\theta}) = \\color{blue}{\\frac{1}{2}\\log\\det{\\mathbf{K}}} + \\color{red}{\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "      clf\n",
    "      lambda1 = 3;\n",
    "      lambda2 = 1;\n",
    "      t = linspace(-pi, pi, 200);\n",
    "      R = [sqrt(2)/2 -sqrt(2)/2; sqrt(2)/2 sqrt(2)/2];\n",
    "      xy = R*[lambda1*sin(t); lambda2*cos(t)];\n",
    "      line(xy(1, :), xy(2, :), 'linewidth', 3, 'color', blackColor);\n",
    "      axis off, axis equal\n",
    "      a = arrow([0 lambda1*R(1, 1)], [0 lambda1*R(2, 1)]);\n",
    "      set(a, 'linewidth', 3, 'color', blueColor);\n",
    "      a = arrow([0 lambda2*R(1, 2)], [0 lambda2*R(2, 2)]);\n",
    "      set(a, 'linewidth', 3, 'color', blueColor);\n",
    "      xlim = get(gca, 'xlim');\n",
    "      xspan = xlim(2) - xlim(1);\n",
    "      ylim = get(gca, 'ylim');\n",
    "      yspan = ylim(2) - ylim(1);\n",
    "      text(lambda1*0.5*R(1, 1)-0.05*xspan, lambda1*0.5*R(2, 1)-yspan*0.05, '$\\eigenvalue_1$')\n",
    "      text(lambda2*0.5*R(1, 2)-0.05*xspan, lambda2*0.5*R(2, 2)-yspan*0.05, '$\\eigenvalue_2$')\n",
    "      fileName = 'gpOptimiseEigen';\n",
    "      printLatexPlot(fileName, directory, 0.45*textWidth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity Control through the Determinant\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-capacity.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-capacity.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The parameters are *inside* the covariance function (matrix).\n",
    "$$k_{i, j} = k(\\mathbf{ x}_i, \\mathbf{ x}_j; \\boldsymbol{ \\theta})$$\n",
    "\n",
    "$$\\mathbf{K}= \\mathbf{R}\\boldsymbol{ \\Lambda}^2 \\mathbf{R}^\\top$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpoptimizePlot1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img class=\"negate\" src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimize-eigen.png\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "$\\boldsymbol{ \\Lambda}$ represents distance on axes. $\\mathbf{R}$ gives\n",
    "rotation.\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "-   $\\boldsymbol{ \\Lambda}$ is *diagonal*,\n",
    "    $\\mathbf{R}^\\top\\mathbf{R}= \\mathbf{I}$.\n",
    "-   Useful representation since\n",
    "    $\\det{\\mathbf{K}} = \\det{\\boldsymbol{ \\Lambda}^2} = \\det{\\boldsymbol{ \\Lambda}}^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlai\n",
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagrams = './gp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_capacity(rotate_angle=np.pi/4, lambda1 = 0.5, lambda2 = 0.3, diagrams = './gp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise-determinant009.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The determinant of the covariance is dependent only on the\n",
    "eigenvalues. It represents the ‘footprint’ of the Gaussian.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    clf\n",
    "    includeText = [];\n",
    "    counter = 0;\n",
    "    plotWidth = 0.6*textWidth;\n",
    "    lambda1 = 3;\n",
    "    lambda2 = 1;\n",
    "    t = linspace(-pi, pi, 200);\n",
    "    R = [sqrt(2)/2 -sqrt(2)/2; sqrt(2)/2 sqrt(2)/2];\n",
    "    xy = [lambda1*sin(t); lambda2*cos(t)];\n",
    "    contourHand = line(xy(1, :), xy(2, :), 'color', blackColor);\n",
    "    xy = [lambda1*sin(t); lambda2*cos(t)]*2;\n",
    "    lim = [-1 1]*max([lambda1 lambda2])*2.2;\n",
    "    set(gca, 'xlim', lim, 'ylim', lim)\n",
    "    axis equal\n",
    "\n",
    "\n",
    "    contourHand = [contourHand line(xy(1, :), xy(2, :), 'color', blackColor)];\n",
    "    set(contourHand, 'linewidth', 2, 'color', redColor)\n",
    "    arrowHand = arrow([0 lambda1], [0 0]);\n",
    "    arrowHand = [arrowHand arrow([0 0], [0 lambda2])];\n",
    "    set(arrowHand, 'linewidth', 3, 'color', blackColor);\n",
    "    xlim = get(gca, 'xlim');\n",
    "    xspan = xlim(2) - xlim(1);\n",
    "    ylim = get(gca, 'ylim');\n",
    "    yspan = ylim(2) - ylim(1);\n",
    "    eigLabel = text(lambda1*0.5, -yspan*0.05, '$\\eigenvalue_1$', 'horizontalalignment', 'center');\n",
    "    eigLabel = [eigLabel text(-0.05*xspan, lambda2*0.5, '$\\eigenvalue_2$', 'horizontalalignment', 'center')];\n",
    "    xlabel('$\\dataScalar_1$')\n",
    "    ylabel('$\\dataScalar_2$')\n",
    "    \n",
    "    box off\n",
    "    xlim = get(gca, 'xlim');\n",
    "    ylim = get(gca, 'ylim');\n",
    "    line([xlim(1) xlim(1)], ylim, 'color', blackColor)\n",
    "    line(xlim, [ylim(1) ylim(1)], 'color', blackColor)\n",
    "    \n",
    "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
    "    printLatexPlot(fileName, directory, plotWidth);\n",
    "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
    "    counter = counter + 1;\n",
    "\n",
    "    y = [1.2 1.4];\n",
    "    dataHand = line(y(1), y(2), 'marker', 'x', 'markersize', markerSize, 'linewidth', markerWidth, 'color', blackColor);\n",
    "    \n",
    "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
    "    printLatexPlot(fileName, directory, plotWidth);\n",
    "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
    "    counter = counter + 1;\n",
    "\n",
    "    \n",
    "    rotateObject(rotationMatrix, arrowHand);\n",
    "    rotateObject(rotationMatrix, contourHand);\n",
    "    rotateObject(rotationMatrix, eigLabel);\n",
    "    \n",
    "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
    "    printLatexPlot(fileName, directory, plotWidth);\n",
    "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
    "    counter = counter + 1;\n",
    "    \n",
    "    printLatexText(includeText, 'gpOptimiseQuadraticIncludeText.tex', directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise-quadratic002.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>The data fit term of the Gaussian process is a quadratic loss\n",
    "centered around zero. This has eliptical contours, the principal axes of\n",
    "which are given by the covariance matrix.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Data Fit\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-data-fit.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-data-fit.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fit Term\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-data-fit-capacity.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/gp-optimize-data-fit-capacity.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy\n",
    "import mlai.plot\n",
    "import mlai\n",
    "import gp_tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(125)\n",
    "diagrams = './gp'\n",
    "\n",
    "black_color=[0., 0., 0.]\n",
    "red_color=[1., 0., 0.]\n",
    "blue_color=[0., 0., 1.]\n",
    "magenta_color=[1., 0., 1.]\n",
    "fontsize=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lim = [-2.2, 2.2]\n",
    "y_ticks = [-2, -1, 0, 1, 2]\n",
    "x_lim = [-2, 2]\n",
    "x_ticks = [-2, -1, 0, 1, 2]\n",
    "err_y_lim = [-12, 20]\n",
    "\n",
    "linewidth=3\n",
    "markersize=15\n",
    "markertype='.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 6)[:, np.newaxis]\n",
    "xtest = np.linspace(x_lim[0], x_lim[1], 200)[:, np.newaxis]\n",
    "\n",
    "# True data\n",
    "true_kern = GPy.kern.RBF(1) + GPy.kern.White(1)\n",
    "true_kern.rbf.lengthscale = 1.0\n",
    "true_kern.white.variance = 0.01\n",
    "K = true_kern.K(x) \n",
    "y = np.random.multivariate_normal(np.zeros((6,)), K, 1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitted model\n",
    "kern = GPy.kern.RBF(1) + GPy.kern.White(1)\n",
    "kern.rbf.lengthscale = 1.0\n",
    "kern.white.variance = 0.01\n",
    "\n",
    "lengthscales = np.asarray([0.01, 0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16, 100])\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=plot.one_figsize)    \n",
    "fig2, ax2 = plt.subplots(figsize=plot.one_figsize)    \n",
    "line = ax2.semilogx(np.NaN, np.NaN, 'x-', \n",
    "                    color=black_color)\n",
    "ax.set_ylim(err_y_lim)\n",
    "ax.set_xlim([0.025, 32])\n",
    "ax.grid(True)\n",
    "ax.set_xticks([0.01, 0.1, 1, 10, 100])\n",
    "ax.set_xticklabels(['$10^{-2}$', '$10^{-1}$', '$10^0$', '$10^1$', '$10^2$'])\n",
    "\n",
    "\n",
    "err = np.zeros_like(lengthscales)\n",
    "err_log_det = np.zeros_like(lengthscales)\n",
    "err_fit = np.zeros_like(lengthscales)\n",
    "\n",
    "counter = 0\n",
    "for i, ls in enumerate(lengthscales):\n",
    "        kern.rbf.lengthscale=ls\n",
    "        K = kern.K(x) \n",
    "        invK, L, Li, log_det_K = GPy.util.linalg.pdinv(K)\n",
    "        err[i] = 0.5*(log_det_K + np.dot(np.dot(y.T,invK),y))\n",
    "        err_log_det[i] = 0.5*log_det_K\n",
    "        err_fit[i] = 0.5*np.dot(np.dot(y.T,invK), y)\n",
    "        Kx = kern.K(x, xtest)\n",
    "        ypred_mean = np.dot(np.dot(Kx.T, invK), y)\n",
    "        ypred_var = kern.Kdiag(xtest) - np.sum((np.dot(Kx.T,invK))*Kx.T, 1)\n",
    "        ypred_sd = np.sqrt(ypred_var)\n",
    "        ax1.clear()\n",
    "        _ = gp_tutorial.gpplot(xtest.flatten(),\n",
    "                               ypred_mean.flatten(),\n",
    "                               ypred_mean.flatten()-2*ypred_sd.flatten(),\n",
    "                               ypred_mean.flatten()+2*ypred_sd.flatten(), \n",
    "                               ax=ax1)\n",
    "        x_lim = ax1.get_xlim()\n",
    "        ax1.set_ylabel('$f(x)$', fontsize=fontsize)\n",
    "        ax1.set_xlabel('$x$', fontsize=fontsize)\n",
    "\n",
    "        p = ax1.plot(x, y, markertype, color=black_color, markersize=markersize, linewidth=linewidth)\n",
    "        ax1.set_ylim(y_lim)\n",
    "        ax1.set_xlim(x_lim)                                    \n",
    "        ax1.set_xticks(x_ticks)\n",
    "        #ax.set(box=False)\n",
    "           \n",
    "        ax1.plot([x_lim[0], x_lim[0]], y_lim, color=black_color)\n",
    "        ax1.plot(x_lim, [y_lim[0], y_lim[0]], color=black_color)\n",
    "\n",
    "        file_name = 'gp-optimise{counter:0>3}.svg'.format(counter=counter)\n",
    "        mlai.write_figure(os.path.join(diagrams, file_name),\n",
    "                          figure=fig1,\n",
    "                          transparent=True)\n",
    "        counter += 1\n",
    "\n",
    "        ax2.clear()\n",
    "        t = ax2.semilogx(lengthscales[0:i+1], err[0:i+1], 'x-', \n",
    "                        color=magenta_color, \n",
    "                        markersize=markersize,\n",
    "                        linewidth=linewidth)\n",
    "        t2 = ax2.semilogx(lengthscales[0:i+1], err_log_det[0:i+1], 'x-', \n",
    "                         color=blue_color, \n",
    "                        markersize=markersize,\n",
    "                        linewidth=linewidth)\n",
    "        t3 = ax2.semilogx(lengthscales[0:i+1], err_fit[0:i+1], 'x-', \n",
    "                         color=red_color, \n",
    "                        markersize=markersize,\n",
    "                        linewidth=linewidth)\n",
    "        ax2.set_ylim(err_y_lim)\n",
    "        ax2.set_xlim([0.025, 32])\n",
    "        ax2.set_xticks([0.01, 0.1, 1, 10, 100])\n",
    "        ax2.set_xticklabels(['$10^{-2}$', '$10^{-1}$', '$10^0$', '$10^1$', '$10^2$'])\n",
    "\n",
    "        ax2.grid(True)\n",
    "\n",
    "        ax2.set_ylabel('negative log likelihood', fontsize=fontsize)\n",
    "        ax2.set_xlabel('length scale, $\\ell$', fontsize=fontsize)\n",
    "        file_name = 'gp-optimise{counter:0>3}.svg'.format(counter=counter)\n",
    "        mlai.write_figure(os.path.join(diagrams, file_name),\n",
    "                          figure=fig2,\n",
    "                          transparent=True)\n",
    "        counter += 1\n",
    "        #ax.set_box(False)\n",
    "        xlim = ax2.get_xlim()\n",
    "        ax2.plot([xlim[0], xlim[0]], err_y_lim, color=black_color)\n",
    "        ax2.plot(xlim, [err_y_lim[0], err_y_lim[0]], color=black_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise006.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise010.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise016.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/gp-optimise021.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Variation in the data fit term, the capacity term and the\n",
    "negative log likelihood for different lengthscales.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponentiated Quadratic Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/eq-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/eq-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.eq_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=eq_cov,\n",
    "                     name='Exponentiated Quadratic',\n",
    "                     shortname='eq',                     \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\exp\\left(-\\frac{\\ltwoNorm{\\inputVector-\\inputVector^\\prime}^2}{2\\lengthScale^2}\\right)',\n",
    "                     lengthscale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exponentiated quadratic covariance, also known as the Gaussian\n",
    "covariance or the RBF covariance and the squared exponential. Covariance\n",
    "between two points is related to the negative exponential of the squared\n",
    "distnace between those points. This covariance function can be derived\n",
    "in a few different ways: as the infinite limit of a radial basis\n",
    "function neural network, as diffusion in the heat equation, as a\n",
    "Gaussian filter in *Fourier space* or as the composition as a series of\n",
    "linear filters applied to a base function.\n",
    "\n",
    "The covariance takes the following form, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2\\ell^2}\\right)\n",
    "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
    "$\\alpha$ represents the overall process variance.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2\\ell^2}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/eq_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/eq_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The exponentiated quadratic covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where Did This Covariance Matrix Come From?\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/computing-rbf-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/computing-rbf-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "$$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}- \\mathbf{ x}^\\prime\\right\\Vert^2_2}{2\\ell^2}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlai import exponentiated_quadratic, Kernel\n",
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
    "kernel = Kernel(exponentiated_quadratic, lengthscale=2.0, variance=1.0)\n",
    "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4]]), \n",
    "                          formula=formula,\n",
    "                          stub='eq_three')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('computing_eq_three_covariance{sample:0>3}.svg', \n",
    "                            directory='./kern', \n",
    "                            sample=IntSlider(0, 0, 16, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//kern/computing_eq_three_covariance016.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
    "covariance function.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlai import exponentiated_quadratic, Kernel\n",
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
    "kernel = Kernel(exponentiated_quadratic, lengthscale=2.0, variance=1.0)\n",
    "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4], [2.0]]), \n",
    "                          formula=formula,\n",
    "                          stub='eq_four')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('computing_eq_four_covariance{sample:0>3}.svg', \n",
    "                            directory='./kern', \n",
    "                            sample=IntSlider(0, 0, 27, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//kern/computing_eq_four_covariance027.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
    "covariance function.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlai import exponentiated_quadratic, Kernel\n",
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = r\"$k(x_i, x_j)=\\alpha\\exp\\left(-\\frac{\\left|\\left|x_i-x_j\\right|\\right|^{2}}{2\\ell^{2}}\\right)$\"\n",
    "kernel = Kernel(exponentiated_quadratic, lengthscale=5.0, variance=2.0)\n",
    "plot.computing_covariance(kernel=kernel, x=np.asarray([[-3.],[1.2], [1.4]]), \n",
    "                          formula=formula,\n",
    "                          stub='eq_three_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "from ipywidgets import IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu.display_plots('computing_eq_three_2_covariance{sample:0>3}.svg', \n",
    "                            directory='./kern', \n",
    "                            sample=IntSlider(0, 0, 16, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//kern/computing_eq_three_2_covariance016.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Entrywise fill in of the covariance matrix from the\n",
    "covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brownian Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/brownian-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/brownian-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.brownian_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.linspace(0, 2, 200)[:, np.newaxis]\n",
    "kernel = mlai.Kernel(function=brownian_cov,\n",
    "                     name='Brownian',\n",
    "                     formula='\\kernelScalar(t, t^\\prime)=\\alpha \\min(t, t^\\prime)',\n",
    "                     shortname='brownian')\n",
    "plot.covariance_func(kernel, t, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brownian motion is also a Gaussian process. It follows a Gaussian random\n",
    "walk, with diffusion occuring at each time point driven by a Gaussian\n",
    "input. This implies it is both Markov and Gaussian. The covariance\n",
    "function for Brownian motion has the form $$\n",
    "k(t, t^\\prime)=\\alpha \\min(t, t^\\prime)\n",
    "$$\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(t, t^\\prime)=\\alpha \\min(t, t^\\prime)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/brownian_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/brownian_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Brownian motion covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where did this covariance matrix come from?\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/precision-matrices.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/precision-matrices.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "**Markov Process**\n",
    "\n",
    "**Visualization of inverse covariance (precision).**\n",
    "\n",
    "-   Precision matrix is sparse: only neighbours in matrix are non-zero.\n",
    "\n",
    "-   This reflects *conditional* independencies in data.\n",
    "\n",
    "-   In this case *Markov* structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where did this covariance matrix come from?\n",
    "\n",
    "**Exponentiated Quadratic**\n",
    "\n",
    "**Visualization of inverse covariance (precision).**\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "-   Precision matrix is not sparse.\n",
    "-   Each point is dependent on all the others.\n",
    "-   In this case non-Markovian.\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "rbfprecisionSample\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance Functions\n",
    "\n",
    "**Markov Process**\n",
    "\n",
    "**Visualization of inverse covariance (precision).**\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"50%\">\n",
    "\n",
    "-   Precision matrix is sparse: only neighbours in matrix are non-zero.\n",
    "-   This reflects *conditional* independencies in data.\n",
    "-   In this case *Markov* structure.\n",
    "\n",
    "</td>\n",
    "<td width=\"50%\">\n",
    "\n",
    "markovprecisionPlot\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/ou-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/ou-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.eq_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=ou_cov,\n",
    "                     name='Ornstein Uhlenbeck',\n",
    "                     shortname='ou',                     \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\exp\\left(-\\frac{\\ltwoNorm{\\inputVector-\\inputVector^\\prime}}{\\lengthScale}\\right)',\n",
    "                     lengthscale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expontential covariance, in one dimension this is also known as the\n",
    "Ornstein Uhlenbeck covariance, and in multiple dimensions it’s also the\n",
    "Mater 1/2 covaraince. It has an interpretation as a stochastic\n",
    "differential equation with a linear drift term (equivalent to a\n",
    "quadratic potential). The drift keeps the covariance stationary (unlike\n",
    "the Brownian motion covariance). It also has an interpretation as a\n",
    "Cauchy filter in Fourier space (Stein, 1999) (from Bochner’s theorem).\n",
    "\n",
    "The covariance takes the following form, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)\n",
    "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
    "$\\alpha$ represents the overall process variance.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/ou_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/ou_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The exponential covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basis Function Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/basis-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/basis-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The fixed basis function covariance just comes from the properties of a\n",
    "multivariate Gaussian, if we decide $$\n",
    "\\mathbf{ f}=\\boldsymbol{ \\Phi}\\mathbf{ w}\n",
    "$$ and then we assume $$\n",
    "\\mathbf{ w}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha\\mathbf{I}\\right)\n",
    "$$ then it follows from the properties of a multivariate Gaussian that\n",
    "$$\n",
    "\\mathbf{ f}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top\\right)\n",
    "$$ meaning that the vector of observations from the function is jointly\n",
    "distributed as a Gaussian process and the covariance matrix is\n",
    "$\\mathbf{K}= \\alpha\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top$, each\n",
    "element of the covariance matrix can then be found as the inner product\n",
    "between two rows of the basis funciton matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.basis_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis = mlai.Basis(function=radial, \n",
    "                   number=3,\n",
    "                   data_limits=[-0.5, 0.5], \n",
    "                   width=0.125)\n",
    "kernel = mlai.Kernel(function=basis_cov,\n",
    "                     name='Basis',\n",
    "                     shortname='basis',                  \n",
    "                     formula='\\kernel(\\inputVector, \\inputVector^\\prime) = \\basisVector(\\inputVector)^\\top \\basisVector(\\inputVector^\\prime)',\n",
    "                     basis=basis)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\boldsymbol{ \\phi}(\\mathbf{ x})^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}^\\prime)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/basis_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/basis_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>A covariance function based on a non-linear basis given by\n",
    "$\\boldsymbol{ \\phi}(\\mathbf{ x})$.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degenerate Covariance Functions\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/rbf-basis-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/rbf-basis-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Any linear basis function can also be incorporated into a covariance\n",
    "function. For example, an RBF network is a type of neural network with a\n",
    "set of radial basis functions. Meaning, the basis funciton is radially\n",
    "symmetric. These basis functions take the form, $$\n",
    "\\phi_k(x) = \\exp\\left(-\\frac{\\left\\Vert x-\\mu_k \\right\\Vert_2^{2}}{\\ell^{2}}\\right).\n",
    "$$ Given a set of parameters, $$\n",
    "\\boldsymbol{ \\mu}= \\begin{bmatrix} -1 \\\\ 0 \\\\ 1\\end{bmatrix},\n",
    "$$ we can construct the corresponding covariance function, which has the\n",
    "form, $$\n",
    "k\\left(\\mathbf{ x},\\mathbf{ x}^{\\prime}\\right)=\\alpha\\boldsymbol{ \\phi}(\\mathbf{ x})^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}^\\prime).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bochners Theoerem\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/boechners-theorem.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/boechners-theorem.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "$$\n",
    "  Q(t) = \\int_{\\mathbb{R}} e^{-itx} \\text{d} \\mu(x).\n",
    "  $$\n",
    "\n",
    "Imagine we are given data and we wish to generalize from it. Without\n",
    "making further assumptions, we have no more information than the given\n",
    "data set. We can think of this ssomewhat like a weighted sum of Dirac\n",
    "delta functions. The Dirac delta function is defined to be a function\n",
    "with an integral of one, which is zero at all places apart from zero,\n",
    "where it is infinite. Given observations at particular times (or\n",
    "locations) $\\mathbf{ x}_i$ we can think of our observations as being a\n",
    "function, $$\n",
    "f(\\mathbf{ x}) = \\sum_{i=1}^ny_i \\delta(\\mathbf{ x}-\\mathbf{ x}_i),\n",
    "$$ This function is highly discontinuous, imagine if we wished to smooth\n",
    "it by filtering in Fourier space. The Fourier transform of a function is\n",
    "given by, $$\n",
    "F(\\boldsymbol{\\omega}) = \\int_{-\\infty}^\\infty f(\\mathbf{ x}) \\exp\\left(-i2\\pi \\boldsymbol{\\omega}^\\top \\mathbf{ x}\\right) \\text{d} \\mathbf{ x}\n",
    "$$ and since our function is a series of delta functions the the\n",
    "transform is easy to compute, $$\n",
    "F(\\boldsymbol{\\omega}) = \\sum_{i=1}^ny_i\\exp\\left(-i 2\\pi \\boldsymbol{\\omega}^\\top \\mathbf{ x}_i\\right)\n",
    "$$ which has a real part given by a weighted sum of cosines and a\n",
    "complex part given by a weighted sum of sines.\n",
    "\n",
    "One theorem that gives insight into covariances is Bochner’s theorem.\n",
    "Bochner’s theorem states that any positive filter in Fourier space gives\n",
    "rise to a valid covariance function. Further, it gives a relationship\n",
    "between the filter and the form of the covariance function. The form of\n",
    "the covariance is given by the [Fourier\n",
    "transform](http://en.wikipedia.org/wiki/Fourier_transform) of the\n",
    "filter, with the argument of the transform being replaced by the\n",
    "distance between the points.\n",
    "\n",
    "Fourier space is a transformed space of the original function to a new\n",
    "basis. The transformation occurs through a convolution with a sine and\n",
    "cosine basis. Given a function of time $f(t)$ the Fourier transform\n",
    "moves it to a weighted linear sum of a sine and cosine basis, $$\n",
    "F(\\omega) = \\int_{-\\infty}^\\infty f(t) \\left[\\cos(2\\pi \\omega t) - i \\sin(2\\pi \\omega t) \\right]\\text{d} t\n",
    "$$ where is the imaginary basis, $i=\\sqrt{-1}$. Through Euler’s formula,\n",
    "$$\n",
    "\\exp(ix) = \\cos x + i\\sin x \n",
    "$$ we can re-express this form as $$\n",
    "F(\\omega) = \\int_{-\\infty}^\\infty f(t) \\exp(-i 2\\pi\\omega)\\text{d} t\n",
    "$$ which is a standard form for the Fourier transform. Fourier’s theorem\n",
    "was that the *inverse* transform can also be expressed in a similar form\n",
    "so we have $$\n",
    "f(t) = \\int_{-\\infty}^\\infty F(\\omega) \\exp(2\\pi\\omega)\\text{d} \\omega.\n",
    "$$ Although we’ve introduced the transform in the context of time\n",
    "Fourier’s interest was an analytical theory of heat and the transform\n",
    "can be applied to a multidimensional spatial function, $f(\\mathbf{ x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import notutils as nu\n",
    "nu.display_google_book(id='TDQJAAAAIAAJ', page='PA525')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinc Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/sinc-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/sinc-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Another approach to developing covariance function exploits Bochner’s\n",
    "theorem Bochner (1959). Bochner’s theorem tells us that any positve\n",
    "filter in Fourier space implies has an associated Gaussian process with\n",
    "a stationary covariance function. The covariance function is the\n",
    "*inverse Fourier transform* of the filter applied in Fourier space.\n",
    "\n",
    "For example, in signal processing, *band limitations* are commonly\n",
    "applied as an assumption. For example, we may believe that no frequency\n",
    "above $w=2$ exists in the signal. This is equivalent to a rectangle\n",
    "function being applied as a the filter in Fourier space.\n",
    "\n",
    "The inverse Fourier transform of the rectangle function is the\n",
    "$\\text{sinc}(\\cdot)$ function. So the sinc is a valid covariance\n",
    "function, and it represents *band limited* signals.\n",
    "\n",
    "Note that other covariance functions we’ve introduced can also be\n",
    "interpreted in this way. For example, the exponentiated quadratic\n",
    "covariance function can be Fourier transformed to see what the implied\n",
    "filter in Fourier space is. The Fourier transform of the exponentiated\n",
    "quadratic is an exponentiated quadratic, so the standard EQ-covariance\n",
    "implies a EQ filter in Fourier space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.sinc_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mlai.Kernel(function=sinc_cov,\n",
    "                     name='Sinc',\n",
    "                     shortname='sinc',                   \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\text{sinc}\\left(\\pi w r\\right)',\n",
    "                     w=2)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\text{sinc}\\left(\\pi w r\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/sinc_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/sinc_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Sinc covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matérn 3/2 Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/matern32-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/matern32-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.matern32_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=matern32_cov,\n",
    "                     name='Matérn 3/2',\n",
    "                     shortname='matern32',                   \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{3}\\ltwoNorm{\\inputVector-\\inputVector^\\prime}}{\\lengthScale}\\right)\\exp\\left(-\\frac{\\sqrt{3}\\ltwoNorm{\\inputVector-\\inputVector^\\prime}}{\\lengthScale}\\right)',\n",
    "                     lengthscale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matérn 3/2 (Stein, 1999) covariance is which is once differentiable,\n",
    "it arises from applying a Student-$t$ based filter in Fourier space with\n",
    "three degrees of freedom.\n",
    "\n",
    "The covariance takes the following form, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{3}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)\\exp\\left(-\\frac{\\sqrt{3}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)\n",
    "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
    "$\\alpha$ represents the overall process variance.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{3}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)\\exp\\left(-\\frac{\\sqrt{3}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/matern32_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/matern32_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The Matérn 3/2 covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matérn 5/2 Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/matern52-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/matern52-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.matern52_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=matern52_cov,\n",
    "                     name='Matérn 5/2',\n",
    "                     shortname='matern52',                   \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{5}\\ltwoNorm{\\inputVector-\\inputVector^\\prime}}{\\lengthScale} + \\frac{5\\ltwoNorm{\\inputVector-\\inputVector^\\prime}^2}{3\\lengthScale^2}\\right)\\exp\\left(-\\frac{\\sqrt{5}\\ltwoNorm{\\inputVector-\\inputVector^\\prime}}{\\lengthScale}\\right)',\n",
    "                     lengthscale=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Matérn 5/2 (Stein, 1999) covariance is which is once differentiable,\n",
    "it arises from applying a Student-$t$ based filter in Fourier space with\n",
    "five degrees of freedom.\n",
    "\n",
    "The covariance takes the following form, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{5}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell} + \\frac{5\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{3\\ell^2}\\right)\\exp\\left(-\\frac{\\sqrt{5}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)\n",
    "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
    "$\\alpha$ represents the overall process variance.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\sqrt{5}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell} + \\frac{5\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{3\\ell^2}\\right)\\exp\\left(-\\frac{\\sqrt{5}\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2}{\\ell}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/matern52_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/matern52_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The Matérn 5/2 covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rational Quadratic Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/ratquad-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/ratquad-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.ratquad_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=ratquad_cov,\n",
    "                     name='Rational Quadratic',\n",
    "                     shortname='ratquad',                    \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\left(1+\\frac{\\ltwoNorm{\\inputVector-\\inputVector^\\prime}^2}{2 a \\lengthScale^2}\\right)^{-a}',\n",
    "                     lengthscale=0.2,\n",
    "                     alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rational quadratic covariance function is derived by a continuous\n",
    "mixture of exponentiated quadratic covariance funcitons, where the\n",
    "lengthscale is given by an inverse gamma distribution. The resulting\n",
    "covariance is infinitely smooth (in terms of differentiability) but has\n",
    "a family of length scales present. As $a$ gets larger, the exponentiated\n",
    "quadratic covariance funciton is recovered.\n",
    "\n",
    "The covariance takes the following form, $$\n",
    "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2 a \\ell^2}\\right)^{-a}\n",
    "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
    "$\\alpha$ represents the overall process variance and $a$ represents\n",
    "shape parameter of the inverse Gamma used to create the scale mixture.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\left(1+\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2 a \\ell^2}\\right)^{-a}$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/ratquad_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/ratquad_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The rational quadratic covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/poly-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/poly-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.polynomial_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mlai.Kernel(function=polynomial_cov,\n",
    "                     name='Polynomial',\n",
    "                     shortname='polynomial',                     \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha(w \\inputVector^\\top\\inputVector^\\prime + b)^d',\n",
    "                     degree=5)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha(w \\mathbf{ x}^\\top\\mathbf{ x}^\\prime + b)^d$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/polynomial_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/polynomial_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Polynomial covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periodic Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/periodic-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/periodic-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.periodic_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mlai.Kernel(function=periodic_cov,\n",
    "                     name='Periodic',\n",
    "                     shortname='periodic',                   \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha\\exp\\left(\\frac{-2\\sin(\\pi rw)^2}{\\lengthScale^2}\\right)',\n",
    "                     lengthscale=1.0)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha\\exp\\left(\\frac{-2\\sin(\\pi rw)^2}{\\ell^2}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/periodic_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/periodic_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Periodic covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/mlp-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/mlp-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.mlp_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mlai.Kernel(function=mlp_cov,\n",
    "                     name='Multilayer Perceptron',\n",
    "                     shortname='mlp',                    \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\arcsin\\left(\\frac{w \\inputVector^\\top \\inputVector^\\prime + b}{\\sqrt{\\left(w \\inputVector^\\top \\inputVector + b + 1\\right)\\left(w \\left.\\inputVector^\\prime\\right.^\\top \\inputVector^\\prime + b + 1\\right)}}\\right)',\n",
    "                     w=5, b=0.5)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-layer perceptron (MLP) covariance, also known as the neural\n",
    "network covariance or the arcsin covariance, is derived by considering\n",
    "the infinite limit of a neural network.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\arcsin\\left(\\frac{w \\mathbf{ x}^\\top \\mathbf{ x}^\\prime + b}{\\sqrt{\\left(w \\mathbf{ x}^\\top \\mathbf{ x}+ b + 1\\right)\\left(w \\left.\\mathbf{ x}^\\prime\\right.^\\top \\mathbf{ x}^\\prime + b + 1\\right)}}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/mlp_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/mlp_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>The multi-layer perceptron covariance function. This is\n",
    "derived by considering the infinite limit of a neural network with\n",
    "probit activation functions.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RELU Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/relu-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/relu-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.relu_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot\n",
    "import mlai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mlai.Kernel(function=relu_cov,\n",
    "                     name='RELU',\n",
    "                     shortname='relu',                   \n",
    "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\arcsin\\left(\\frac{w \\inputVector^\\top \\inputVector^\\prime + b}{\\sqrt{\\left(w \\inputVector^\\top \\inputVector + b + 1\\right)\\left(w \\left.\\inputVector^\\prime\\right.^\\top \\inputVector^\\prime + b + 1\\right)}}\\right)',\n",
    "                     w=5, b=0.5)\n",
    "                     \n",
    "plot.covariance_func(kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \n",
    "\\alpha \\arcsin\\left(\\frac{w \\mathbf{ x}^\\top \\mathbf{ x}^\\prime + b}\n",
    "{\\sqrt{\\left(w \\mathbf{ x}^\\top \\mathbf{ x}+ b + 1\\right)\n",
    "\\left(w \\left.\\mathbf{ x}^\\prime\\right.^\\top \\mathbf{ x}^\\prime + b + 1\\right)}}\\right)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/relu_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/relu_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>Rectified linear unit covariance function.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/add-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/add-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.linear_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.eq_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.add_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=add_cov,\n",
    "                     name='Additive',\n",
    "                     shortname='add',                     \n",
    "                     formula='\\kernelScalar_f(\\inputVector, \\inputVector^\\prime) = \\kernelScalar_g(\\inputVector, \\inputVector^\\prime) + \\kernelScalar_h(\\inputVector, \\inputVector^\\prime)', \n",
    "                     kerns=[linear_cov, eq_cov], \n",
    "                     kern_args=[{'variance': 25}, {'lengthscale' : 0.2}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An additive covariance function is derived from considering the result\n",
    "of summing two Gaussian processes together. If the first Gaussian\n",
    "process is $g(\\cdot)$, governed by covariance $k_g(\\cdot, \\cdot)$ and\n",
    "the second process is $h(\\cdot)$, governed by covariance\n",
    "$k_h(\\cdot, \\cdot)$ then the combined process\n",
    "$f(\\cdot) = g(\\cdot) + h(\\cdot)$ is govererned by a covariance function,\n",
    "$$\n",
    "k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) + k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)\n",
    "$$\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) + k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/add_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/add_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>An additive covariance function formed by combining a linear\n",
    "and an exponentiated quadratic covariance functions.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Covariance\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/prod-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/prod-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.linear_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.eq_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load -n mlai.prod_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Kernel(function=prod_cov,\n",
    "                     name='Product',\n",
    "                     shortname='prod',                     \n",
    "                     formula='\\kernelScalar_f(\\inputVector, \\inputVector^\\prime) = \\kernelScalar_g(\\inputVector, \\inputVector^\\prime) \\kernelScalar_h(\\inputVector, \\inputVector^\\prime)', \n",
    "                     kerns=[linear_cov, eq_cov], \n",
    "                     kern_args=[{'variance': 25}, {'lengthscale' : 0.2}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An product covariance function is derived from considering the result of\n",
    "multiplying two stochastic processes together. If the first stochastic\n",
    "process is $g(\\cdot)$, governed by covariance $k_g(\\cdot, \\cdot)$ and\n",
    "the second process is $h(\\cdot)$, governed by covariance\n",
    "$k_h(\\cdot, \\cdot)$ then the combined process\n",
    "$f(\\cdot) = g(\\cdot) h(\\cdot)$ is governed by a covariance function, $$\n",
    "k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)\n",
    "$$ Note that if $g(\\cdot)$ and $h(\\cdot)$ are Gaussian processes then\n",
    "$f(\\cdot)$ will not in general be a Gaussian process. So the base\n",
    "processes are (presumably) some (unspecified) non-Gaussian processes.\n",
    "\n",
    "<center>\n",
    "\n",
    "$$k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)$$\n",
    "\n",
    "</center>\n",
    "<table>\n",
    "<tr>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img src=\"../slides/diagrams/kern/prod_covariance.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "</td>\n",
    "<td width=\"45%\">\n",
    "\n",
    "<img class=\"negate\" src=\"../slides/diagrams/kern/prod_covariance.gif\" style=\"width:100%\">\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "Figure: <i>An product covariance function formed by combining a linear\n",
    "and an exponentiated quadratic covariance functions.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mauna Loa Data\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/mauna-loa-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/mauna-loa-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The Mauna Loa data consists of monthly mean carbon dioxide measured at\n",
    "Mauna Loa Observatory, Hawaii. According to the website,\n",
    "<https://www.esrl.noaa.gov/gmd/ccgg/trends/>.\n",
    "\n",
    "> The carbon dioxide data on Mauna Loa constitute the longest record of\n",
    "> direct measurements of CO2 in the atmosphere. They were started by C.\n",
    "> David Keeling of the Scripps Institution of Oceanography in March of\n",
    "> 1958 at a facility of the National Oceanic and Atmospheric\n",
    "> Administration (Keeling et al., 1976). NOAA started its own CO2\n",
    "> measurements in May of 1974, and they have run in parallel with those\n",
    "> made by Scripps since then (Thoning et al., 1989)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.mauna_loa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, if you’ve downloaded the data before you have a cached version. To\n",
    "download a fresh version of the data I can set `refresh_data=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.mauna_loa(refresh_data=True)\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "offset = y.mean()\n",
    "scale = np.sqrt(y.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data dictionary contains the standard keys ‘X’ and ‘Y’ which give a\n",
    "unidimensional regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (1950,2020)\n",
    "ylim = (310, 420)\n",
    "yhat = (y-offset)/scale\n",
    "\n",
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=2)\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('CO$_2$ concentration in ppm')\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "mlai.write_figure(filename='mauna-loa.svg', \n",
    "                  directory='./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//datasets/mauna-loa.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Mauna Loa data shows carbon dioxide monthly average\n",
    "measurements from the Mauna Loa Observatory in Hawaii.</i>\n",
    "\n",
    "Additionally there are keys `Xtest` and `Ytest` which provide test data.\n",
    "The number of points considered to be *training data* is controlled by\n",
    "the argument `num_train` argument, which defaults to 545. This number is\n",
    "chosen as it matches that used in the [Gaussian Processes for Machine\n",
    "Learning](http://www.gaussianprocess.org/gpml/chapters/RW5.pdf) book\n",
    "(Rasmussen and Williams, 2006, Chapter 5). Below we plot the test and\n",
    "training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = data['Xtest']\n",
    "ytest = data['Ytest']\n",
    "ytesthat = (ytest-offset)/scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=2)\n",
    "_ = ax.plot(xtest, ytest, 'g.',markersize=2)\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('CO$_2$ concentration in ppm')\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "mlai.write_figure(filename='mauna-loa-test.svg', \n",
    "                  directory='./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//datasets/mauna-loa-test.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Mauna Loa test data shows carbon dioxide monthly average\n",
    "measurements from the Mauna Loa Observatory in Hawaii.</i>\n",
    "\n",
    "Of course we have included the citation information for the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['citation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And extra information about the data is included, as standard, under the\n",
    "keys `info` and `details`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['info'])\n",
    "print()\n",
    "print(data['details'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, importantly, for reference you can also check the license for the\n",
    "data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['license'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Fit\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/mauna-loa-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/mauna-loa-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "The data set was used as a demonstration of model selection for Gaussian\n",
    "processes in Rasmussen and Williams (2006) (Chapter 5).\n",
    "\n",
    "Here we reconstruct that analysis in GPy. Our first objective will be to\n",
    "perform a Gaussian process fit to the data, we’ll do this using the [GPy\n",
    "software](https://github.com/SheffieldML/GPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = GPy.kern.RBF(1, lengthscale=40, variance=300)\n",
    "kernel2 = GPy.kern.PeriodicMatern52(1, variance=4, period=1, lengthscale=0.2)\n",
    "kernel3 = GPy.kern.RatQuad(1, lengthscale=5, variance=10, power=1)\n",
    "kernel4 = GPy.kern.RBF(1, lengthscale=0.2, variance=1)\n",
    "kernel5 = GPy.kern.Bias(1, variance=100)\n",
    "kernel = kernel1 + kernel2 + kernel3 + kernel4 + kernel5\n",
    "model = GPy.models.GPRegression(x,yhat, kernel=kernel)\n",
    "model.optimize(messages=True) # Optimize parameters of covariance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command sets up the model, then `model.optimize()` optimizes\n",
    "the parameters of the covariance function and the noise level of the\n",
    "model. Once the fit is complete, we’ll try creating some test points,\n",
    "and computing the output of the GP model in terms of the mean and\n",
    "standard deviation of the posterior functions between 1870 and 2030. We\n",
    "plot the mean function and the standard deviation at 200 locations. We\n",
    "can obtain the predictions using `y_mean, y_var = model.predict(xt)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.linspace(xlim[0],xlim[1],300)[:,np.newaxis]\n",
    "yt_mean, yt_var = model.predict(xt)\n",
    "yt_sd=np.sqrt(yt_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the results using the helper function in `mlai.plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(xt, yt_mean*scale+offset, 'C0', linewidth=3)\n",
    "ax.plot(x, y, 'r.')\n",
    "ax.fill_between(xt[:, 0],\n",
    "                 yt_mean[:, 0]*scale + offset + scale*np.sqrt(yt_var)[:, 0],\n",
    "                 yt_mean[:, 0]*scale + offset - scale*np.sqrt(yt_var)[:, 0], color='C0', alpha=0.6)\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "mlai.write_figure(filename='mauna-loa-gp.svg', \n",
    "                  directory = './gp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/mauna-loa-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the Mauna Loa Observatory data on CO2\n",
    "concentrations.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box Jenkins Airline Passenger Data\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/box-jenkins-airline-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_datasets/includes/box-jenkins-airline-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "This data is giving airline passenger numbers between 1948 and 1960. It\n",
    "was published by Box and Jenkins (1976)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pods.datasets.boxjenkins_airline()\n",
    "x = data['X']\n",
    "y = data['Y']\n",
    "xtest = data['Xtest']\n",
    "ytest = data['Ytest']\n",
    "\n",
    "offset = y.mean()\n",
    "scale = np.sqrt(y.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = (1948,1958)\n",
    "ylim = (50, 400)\n",
    "yhat = (y-offset)/scale\n",
    "\n",
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "_ = ax.plot(x, y, 'r.',markersize=2)\n",
    "ax.set_xlabel('year', fontsize=20)\n",
    "ax.set_ylabel('Passenger numbers', fontsize=20)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('thousands of passengers')\n",
    "\n",
    "mlai.write_figure(filename='box-jenkins-airline.svg', \n",
    "                  directory='./datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//datasets/box-jenkins-airline.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Box-Jenkins data set on airline passenger numbers.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Process Fit\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/box-jenkins-airline-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_gp/includes/box-jenkins-airline-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
    "\n",
    "Here we reconstruct that analysis in GPy. Our first objective will be to\n",
    "perform a Gaussian process fit to the data, we’ll do this using the [GPy\n",
    "software](https://github.com/SheffieldML/GPy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel1 = GPy.kern.RBF(1, lengthscale=40, variance=300)\n",
    "kernel2 = GPy.kern.PeriodicMatern52(1, variance=4, period=1, lengthscale=0.2)\n",
    "kernel3 = GPy.kern.RatQuad(1, lengthscale=5, variance=10, power=1)\n",
    "kernel4 = GPy.kern.RBF(1, lengthscale=0.2, variance=1)\n",
    "kernel5 = GPy.kern.Bias(1, variance=100)\n",
    "kernel = kernel1 + kernel2 + kernel3 + kernel4 + kernel5\n",
    "model = GPy.models.GPRegression(x,yhat, kernel=kernel)\n",
    "model.optimize(messages=True) # Optimize parameters of covariance function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first command sets up the model, then `model.optimize()` optimizes\n",
    "the parameters of the covariance function and the noise level of the\n",
    "model. Once the fit is complete, we’ll try creating some test points,\n",
    "and computing the output of the GP model in terms of the mean and\n",
    "standard deviation of the posterior functions between 1948 and 1958. We\n",
    "plot the mean function and the standard deviation at 200 locations. We\n",
    "can obtain the predictions using `y_mean, y_var = model.predict(xt)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = np.linspace(xlim[0],xlim[1],300)[:,np.newaxis]\n",
    "yt_mean, yt_var = model.predict(xt)\n",
    "yt_sd=np.sqrt(yt_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the results using the helper function in `mlai.plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlai.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "ax.plot(xt, yt_mean*scale+offset, 'C0', linewidth=3)\n",
    "ax.plot(x, y, 'r.')\n",
    "ax.fill_between(xt[:, 0],\n",
    "                 yt_mean[:, 0]*scale +offset + offset*np.sqrt(yt_var)[:, 0],\n",
    "                 yt_mean[:, 0]*scale +offset - offset*np.sqrt(yt_var)[:, 0], color='C0', alpha=0.6)\n",
    "\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "ax.set_xlabel('year')\n",
    "ax.set_ylabel('thousands of passengers')\n",
    "mlai.write_figure(filename='box-jenkins-airline-gp.svg', \n",
    "                  directory = './gp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/box-jenkins-airline-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Gaussian process fit to the Box-Jenkins airline passenger\n",
    "data.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Mixture Kernel\n",
    "\n",
    "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
    "class=\"editsection\"\n",
    "style=\"\"><a href=\"https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/spectral-mixture-kernel.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/talks/edit/gh-pages/_kern/includes/spectral-mixture-kernel.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comps = 10\n",
    "kernel = GPy.kern.ExpQuadCosine(1)\n",
    "for i in range(num_comps-1):\n",
    "    kernel += GPy.kern.ExpQuadCosine(1)\n",
    "\n",
    "kernel+=GPy.kern.Bias(1)\n",
    "kernel.randomize()\n",
    "model = GPy.models.GPRegression(X, y, kernel)\n",
    "#model['.*lengthscale'] = np.random.uniform(0.0, 6.0, size=model['.*lengthscale'].shape)\n",
    "#model['.*bandwidth'] = 2./np.sqrt(np.random.gamma(1.0, 0.5*(X.max()-X.min()), size=model['.*bandwidth'].shape))\n",
    "#model['.*variance'] = 5.0\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "\n",
    "model.plot(ax=ax)\n",
    "\n",
    "mlai.write_figure('box-jenkins-spectral-mixture-gp', directory='./gp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/box-jenkins-spectral-mixture-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Spectral mixture GP as applied to the Box-Jenkins airline\n",
    "data.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comps = 10\n",
    "kernel = GPy.kern.ExpQuadCosine(1)\n",
    "for i in range(num_comps-1):\n",
    "    kernel += GPy.kern.ExpQuadCosine(1)\n",
    "kernel+=GPy.kern.Bias(1)\n",
    "kernel.randomize()\n",
    "model = GPy.models.GPRegression(X, y, kernel)\n",
    "#model['.*frequency'] = np.random.uniform(0.0, 6.0, size=model['.*frequency'].shape)\n",
    "#model['.*bandwidth'] = 2./np.sqrt(np.random.gamma(1.0, 0.5*(X.max()-X.min()), size=model['.*bandwidth'].shape))\n",
    "#model['.*variance'] = 5.0\n",
    "#model['.*bias_variance'] = 90000\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we optimize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize(messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mlai.plot\n",
    "import mlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
    "\n",
    "model.plot(ax=ax)\n",
    "\n",
    "mlai.write_figure('mauna-loa-spectral-mixture-gp', directory='./gp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://inverseprobability.com/talks/./slides/diagrams//gp/mauna-loa-spectral-mixture-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
    "\n",
    "Figure: <i>Spectral mixture GP as applied to the Mauna Loa Observatory\n",
    "carbon dioxide concentration data.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thanks!\n",
    "\n",
    "For more information on these subjects and more you might want to check\n",
    "the following resources.\n",
    "\n",
    "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
    "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
    "-   newspaper: [Guardian Profile\n",
    "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
    "-   blog:\n",
    "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bochner, S., 1959. Lectures on Fourier integrals. Princeton University\n",
    "Press.\n",
    "\n",
    "Box, G.E.P., Jenkins, G.M., 1976. Time series analysis: Forecasting and\n",
    "control. Holden-Day.\n",
    "\n",
    "Keeling, C.D., Bacastow, R.B., Bainbridge, A.E., Ekdahl Jr., C.A.,\n",
    "Guenther, P.R., Waterman, L.S., Chin, J.F.S., 1976. Atmospheric carbon\n",
    "dioxide variations at Mauna Loa Observatory, Hawaii. Tellus 28, 538–551.\n",
    "<https://doi.org/10.1111/j.2153-3490.1976.tb00701.x>\n",
    "\n",
    "Rasmussen, C.E., Williams, C.K.I., 2006. Gaussian processes for machine\n",
    "learning. mit, Cambridge, MA.\n",
    "\n",
    "Stein, M.L., 1999. Interpolation of spatial data: Some theory for\n",
    "Kriging. springer.\n",
    "\n",
    "Thoning, K.W., Tans, P.P., Komhyr, W.D., 1989. Atmospheric carbon\n",
    "dioxide at Mauna Loa Observatory: 2. Analysis of the NOAA GMCC data,\n",
    "1974–1985. Journal of Geophysical Research: Atmospheres 94, 8549–8565.\n",
    "<https://doi.org/10.1029/JD094iD06p08549>"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
